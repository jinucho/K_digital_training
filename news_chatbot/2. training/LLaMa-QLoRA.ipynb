{"cells":[{"cell_type":"markdown","metadata":{"id":"FlTEMQciQS9W"},"source":["# LLaMa-Alpaca-LoRA 파인튜닝\n","\n","나만의 데이터로 ChatGPT 만들기\n","\n","> 유튜브 [빵형의 개발도상국](https://www.youtube.com/@bbanghyong)\n","\n","![](https://github.com/kairess/alpaca-lora/raw/main/result.jpg)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1709881471871,"user":{"displayName":"조진우Jeanu","userId":"17564005012210485344"},"user_tz":-540},"id":"TbpHMW2dIck_","outputId":"c7ff2d0b-a85a-4d93-ec75-bea4cda126c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Mar  8 07:04:30 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0              23W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"xLkPRXXMPInO"},"source":["## Download source code and install dependencies\n","\n","- https://github.com/tloen/alpaca-lora.git\n","- 주의!: bitsandbytes가 현재 Linux에서만 동작함\n","- 주의!!: peft 버그 https://github.com/tloen/alpaca-lora/issues/293"]},{"cell_type":"code","source":["!git clone -q https://github.com/kairess/alpaca-lora.git\n","%cd alpaca-lora"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBa3vqDQPovf","executionInfo":{"status":"ok","timestamp":1709881476032,"user_tz":-540,"elapsed":3186,"user":{"displayName":"조진우Jeanu","userId":"17564005012210485344"}},"outputId":"18d13a76-6fe6-4c52-d954-779f0710ec66"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/alpaca-lora\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57372,"status":"ok","timestamp":1709881548954,"user":{"displayName":"조진우Jeanu","userId":"17564005012210485344"},"user_tz":-540},"id":"XpbGPksUG4Uu","outputId":"2a85cc51-af1b-4bcb-f0d4-04470b569bb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.2/308.2 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -r requirements.txt -q\n","!pip uninstall peft -y -q\n","!pip install -q git+https://github.com/huggingface/peft.git@e536616888d51b453ed354a6f1e243fecb02ea08"]},{"cell_type":"markdown","metadata":{"id":"HZfGYCcyElu3"},"source":["## Dataset\n","\n","### - 49,620개의 Instruction, Input, Response set.\n","\n","- https://github.com/Beomi/KoAlpaca/blob/main/ko_alpaca_data.json\n","- https://huggingface.co/datasets/Bingsu/ko_alpaca_data\n","\n","### - shareGPT 한국어 번역 데이터셋\n","\n","이 프로젝트는 shareGPT 데이터셋 60만 대화문을 DeepL 을 통해 한국어로 번역하고 있습니다.\n","\n","https://huggingface.co/datasets/junelee/sharegpt_deepl_ko\n","\n","```json\n","[\n","  {\n","    \"instruction\":\"직원들의 급여를 기록하는 데이터베이스를 설계하십시오.\",\n","    \"input\":\"\",\n","    \"output\":\"직원들의 급여를 새로운 데이터베이스에서 추적하려면, 다음과 같은 열이 포함된 \\\"Employee\\\" 테이블을 만들어야 합니다: \\\"name\\\", \\\"salary\\\", \\\"start_date\\\", \\\"end_date\\\".\"\n","  },\n","  {\n","    \"instruction\":\"아래 문장의 각 단어에 품사를 지정하십시오.\",\n","    \"input\":\"새끼 고양이는 종종 신나게 뛰어다니기도 합니다.\",\n","    \"output\":\"새끼(Noun) 고양이(Noun) 는 은 종종 Adverb 신나게 Adverb 뛰어다니기도 합니다.\"\n","  },\n","  ...\n","]\n","```"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V907g2JXFk1N","executionInfo":{"status":"ok","timestamp":1709854194001,"user_tz":-540,"elapsed":26953,"user":{"displayName":"조진우Jeanu","userId":"17564005012210485344"}},"outputId":"2267cf0e-8383-45b7-b2c5-917df048d857"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"id":"DqEfiJIiQFsj","executionInfo":{"status":"ok","timestamp":1709854194001,"user_tz":-540,"elapsed":4,"user":{"displayName":"조진우Jeanu","userId":"17564005012210485344"}},"outputId":"c5072843-f1b6-4bc7-817c-65ff22724204","colab":{"base_uri":"https://localhost:8080/","height":36}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/alpaca-lora'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":1058,"status":"error","timestamp":1709882030745,"user":{"displayName":"조진우Jeanu","userId":"17564005012210485344"},"user_tz":-540},"id":"W73klsce2NdN","outputId":"38e61927-524a-47a4-99e2-59fe218fdca2"},"outputs":[{"output_type":"error","ename":"JSONDecodeError","evalue":"Unterminated string starting at: line 149744 column 18 (char 29304742)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-4d83a09404e1>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/alpaca-lora/custom_data.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcustom_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcustom_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mJSONDecodeError\u001b[0m: Unterminated string starting at: line 149744 column 18 (char 29304742)"]}],"source":["import json\n","\n","with open('/content/alpaca-lora/custom_data.json', 'r') as f:\n","    custom_data = json.load(f)\n","\n","custom_data[:5]"]},{"cell_type":"markdown","metadata":{"id":"I1BQPeff_Coj"},"source":["## Finetune\n","\n","기본 설정으로 했을 때:\n","- 3h/1epoch in NVIDIA A100\n","- 12h/1epoch in NVIDIA T4"]},{"cell_type":"markdown","metadata":{"id":"6cwwJCbf9_yA"},"source":["### Create a custom template\n","\n","Default Alpaca\n","\n","```json\n","{\n","    \"description\": \"Template used by Alpaca-LoRA.\",\n","    \"prompt_input\": \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\",\n","    \"prompt_no_input\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\\n\",\n","    \"response_split\": \"### Response:\"    \n","}\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9_6FMpjS1o6a"},"outputs":[],"source":["import json\n","\n","prompt_template = {\n","    \"description\": \"Alpaca-LoRA Custom 템플릿\",\n","    \"prompt_input\": (\n","        \"Below is an example pairing news article text with questions and answers about the article.\\n\"\n","        \"아래는 뉴스기사 본문과 뉴스기사에 대한 질문 및 그에 대한 답변이 짝을 이루는 예제 입니다.\\n\\n\"\n","        \"Write a response that appropriately completes the request.\\n요청을 적절히 완료하는 응답을 작성하세요.\\n\\n\"\n","        \"### Instruction(질문):\\n{instruction}\\n\\n### Input(뉴스기사):\\n{input}\\n\\n### Response:\\n\"\n","    ),\n","    \"prompt_no_input\": (\n","        \"Below is the news article text along with an explanation of the news article.\\n\"\n","        \"아래는 질문과 그에 대한 답변 입니다.\\n\\n\"\n","        \"Write a response that appropriately completes the question.\\n질문에 대해 적절히 완료하는 응답을 작성하세요.\\n\\n\"\n","        \"### Instruction(질문):\\n{instruction}\\n\\n### Response:\\n\"\n","    ),\n","    \"response_split\": \"### Response:\",\n","}\n","\n","with open('templates/custom.json', 'w', encoding='utf-8') as f:\n","    json.dump(prompt_template, f, ensure_ascii=False)"]},{"cell_type":"markdown","metadata":{"id":"JuOOeDPoTMSb"},"source":["### Hyperparameters\n","\n","https://github.com/tloen/alpaca-lora/blob/0e1a5d52a460d14aea2325e43c302972badb9cdd/finetune.py#L28"]},{"cell_type":"code","source":["# import shutil\n","# shutil.rmtree('/content/alpaca-lora/output')"],"metadata":{"id":"nLglqBLIf4mv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Dw8-wbgIrJ0","outputId":"6a570c09-d05c-463f-ac45-4b591de6e139","executionInfo":{"status":"ok","timestamp":1709823280511,"user_tz":-540,"elapsed":14527246,"user":{"displayName":"조진우Jeanu","userId":"17564005012210485344"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training Alpaca-LoRA model with params:\n","base_model: baffo32/decapoda-research-llama-7B-hf\n","data_path: /content/drive/MyDrive/LLM project/0.프로젝트4_마지막프로젝트_240226/BERT_Training/custom_data.json\n","output_dir: ./output\n","batch_size: 256\n","micro_batch_size: 64\n","num_epochs: 5\n","learning_rate: 5e-05\n","cutoff_len: 256\n","val_set_size: 2000\n","lora_r: 8\n","lora_alpha: 16\n","lora_dropout: 0.05\n","lora_target_modules: ['q_proj', 'v_proj']\n","train_on_inputs: True\n","add_eos_token: False\n","group_by_length: False\n","wandb_project: \n","wandb_run_name: \n","wandb_watch: \n","wandb_log_model: \n","resume_from_checkpoint: False\n","prompt template: custom\n","\n","Loading checkpoint shards: 100% 33/33 [00:15<00:00,  2.13it/s]\n","trainable params: 4194304 || all params: 6742609920 || trainable%: 0.06220594176090199\n","Map: 100% 29993/29993 [01:52<00:00, 266.30 examples/s]\n","Map: 100% 2000/2000 [00:07<00:00, 263.14 examples/s]\n","2024-03-07 10:54:55.948744: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-07 10:54:55.948786: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-07 10:54:55.950403: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-07 10:54:57.104716: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","  0% 0/585 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","{'loss': 1.817, 'learning_rate': 5e-06, 'epoch': 0.09}\n","{'loss': 1.7976, 'learning_rate': 1e-05, 'epoch': 0.17}\n","{'loss': 1.7603, 'learning_rate': 1.5e-05, 'epoch': 0.26}\n","{'loss': 1.7072, 'learning_rate': 2e-05, 'epoch': 0.34}\n","{'loss': 1.62, 'learning_rate': 2.5e-05, 'epoch': 0.43}\n","{'loss': 1.5008, 'learning_rate': 3e-05, 'epoch': 0.51}\n","{'loss': 1.3337, 'learning_rate': 3.5e-05, 'epoch': 0.6}\n","{'loss': 1.0985, 'learning_rate': 4e-05, 'epoch': 0.68}\n","{'loss': 0.7913, 'learning_rate': 4.5e-05, 'epoch': 0.77}\n","{'loss': 0.6399, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.85}\n","{'loss': 0.6046, 'learning_rate': 4.9072164948453605e-05, 'epoch': 0.94}\n","{'loss': 0.5873, 'learning_rate': 4.804123711340206e-05, 'epoch': 1.02}\n","{'loss': 0.5808, 'learning_rate': 4.7010309278350514e-05, 'epoch': 1.11}\n","{'loss': 0.5754, 'learning_rate': 4.5979381443298966e-05, 'epoch': 1.19}\n","{'loss': 0.5694, 'learning_rate': 4.4948453608247424e-05, 'epoch': 1.28}\n","{'loss': 0.5671, 'learning_rate': 4.3917525773195875e-05, 'epoch': 1.36}\n","{'loss': 0.5608, 'learning_rate': 4.2886597938144326e-05, 'epoch': 1.45}\n","{'loss': 0.5623, 'learning_rate': 4.1855670103092784e-05, 'epoch': 1.54}\n","{'loss': 0.5569, 'learning_rate': 4.0824742268041235e-05, 'epoch': 1.62}\n","{'loss': 0.5545, 'learning_rate': 3.979381443298969e-05, 'epoch': 1.71}\n"," 34% 200/585 [1:20:49<2:35:27, 24.23s/it]\n","  0% 0/250 [00:00<?, ?it/s]\u001b[A\n","  1% 2/250 [00:00<00:45,  5.43it/s]\u001b[A\n","  1% 3/250 [00:00<01:04,  3.81it/s]\u001b[A\n","  2% 4/250 [00:01<01:14,  3.30it/s]\u001b[A\n","  2% 5/250 [00:01<01:19,  3.07it/s]\u001b[A\n","  2% 6/250 [00:01<01:24,  2.90it/s]\u001b[A\n","  3% 7/250 [00:02<01:25,  2.83it/s]\u001b[A\n","  3% 8/250 [00:02<01:26,  2.79it/s]\u001b[A\n","  4% 9/250 [00:02<01:27,  2.77it/s]\u001b[A\n","  4% 10/250 [00:03<01:26,  2.76it/s]\u001b[A\n","  4% 11/250 [00:03<01:26,  2.75it/s]\u001b[A\n","  5% 12/250 [00:04<01:26,  2.74it/s]\u001b[A\n","  5% 13/250 [00:04<01:26,  2.73it/s]\u001b[A\n","  6% 14/250 [00:04<01:26,  2.72it/s]\u001b[A\n","  6% 15/250 [00:05<01:26,  2.71it/s]\u001b[A\n","  6% 16/250 [00:05<01:26,  2.70it/s]\u001b[A\n","  7% 17/250 [00:05<01:26,  2.69it/s]\u001b[A\n","  7% 18/250 [00:06<01:25,  2.70it/s]\u001b[A\n","  8% 19/250 [00:06<01:25,  2.69it/s]\u001b[A\n","  8% 20/250 [00:07<01:25,  2.70it/s]\u001b[A\n","  8% 21/250 [00:07<01:24,  2.71it/s]\u001b[A\n","  9% 22/250 [00:07<01:25,  2.67it/s]\u001b[A\n","  9% 23/250 [00:08<01:24,  2.68it/s]\u001b[A\n"," 10% 24/250 [00:08<01:24,  2.68it/s]\u001b[A\n"," 10% 25/250 [00:08<01:23,  2.68it/s]\u001b[A\n"," 10% 26/250 [00:09<01:23,  2.69it/s]\u001b[A\n"," 11% 27/250 [00:09<01:22,  2.69it/s]\u001b[A\n"," 11% 28/250 [00:10<01:22,  2.69it/s]\u001b[A\n"," 12% 29/250 [00:10<01:21,  2.70it/s]\u001b[A\n"," 12% 30/250 [00:10<01:21,  2.71it/s]\u001b[A\n"," 12% 31/250 [00:11<01:21,  2.69it/s]\u001b[A\n"," 13% 32/250 [00:11<01:20,  2.70it/s]\u001b[A\n"," 13% 33/250 [00:11<01:20,  2.70it/s]\u001b[A\n"," 14% 34/250 [00:12<01:19,  2.71it/s]\u001b[A\n"," 14% 35/250 [00:12<01:19,  2.71it/s]\u001b[A\n"," 14% 36/250 [00:12<01:19,  2.71it/s]\u001b[A\n"," 15% 37/250 [00:13<01:18,  2.71it/s]\u001b[A\n"," 15% 38/250 [00:13<01:18,  2.70it/s]\u001b[A\n"," 16% 39/250 [00:14<01:18,  2.70it/s]\u001b[A\n"," 16% 40/250 [00:14<01:17,  2.71it/s]\u001b[A\n"," 16% 41/250 [00:14<01:17,  2.70it/s]\u001b[A\n"," 17% 42/250 [00:15<01:16,  2.71it/s]\u001b[A\n"," 17% 43/250 [00:15<01:16,  2.71it/s]\u001b[A\n"," 18% 44/250 [00:15<01:16,  2.71it/s]\u001b[A\n"," 18% 45/250 [00:16<01:15,  2.71it/s]\u001b[A\n"," 18% 46/250 [00:16<01:15,  2.71it/s]\u001b[A\n"," 19% 47/250 [00:17<01:14,  2.71it/s]\u001b[A\n"," 19% 48/250 [00:17<01:14,  2.71it/s]\u001b[A\n"," 20% 49/250 [00:17<01:14,  2.71it/s]\u001b[A\n"," 20% 50/250 [00:18<01:14,  2.70it/s]\u001b[A\n"," 20% 51/250 [00:18<01:13,  2.70it/s]\u001b[A\n"," 21% 52/250 [00:18<01:13,  2.70it/s]\u001b[A\n"," 21% 53/250 [00:19<01:13,  2.70it/s]\u001b[A\n"," 22% 54/250 [00:19<01:12,  2.70it/s]\u001b[A\n"," 22% 55/250 [00:20<01:12,  2.69it/s]\u001b[A\n"," 22% 56/250 [00:20<01:12,  2.69it/s]\u001b[A\n"," 23% 57/250 [00:20<01:11,  2.69it/s]\u001b[A\n"," 23% 58/250 [00:21<01:11,  2.70it/s]\u001b[A\n"," 24% 59/250 [00:21<01:10,  2.70it/s]\u001b[A\n"," 24% 60/250 [00:21<01:10,  2.70it/s]\u001b[A\n"," 24% 61/250 [00:22<01:10,  2.70it/s]\u001b[A\n"," 25% 62/250 [00:22<01:09,  2.71it/s]\u001b[A\n"," 25% 63/250 [00:22<01:09,  2.71it/s]\u001b[A\n"," 26% 64/250 [00:23<01:08,  2.70it/s]\u001b[A\n"," 26% 65/250 [00:23<01:08,  2.70it/s]\u001b[A\n"," 26% 66/250 [00:24<01:07,  2.71it/s]\u001b[A\n"," 27% 67/250 [00:24<01:07,  2.71it/s]\u001b[A\n"," 27% 68/250 [00:24<01:07,  2.71it/s]\u001b[A\n"," 28% 69/250 [00:25<01:06,  2.70it/s]\u001b[A\n"," 28% 70/250 [00:25<01:06,  2.71it/s]\u001b[A\n"," 28% 71/250 [00:25<01:06,  2.71it/s]\u001b[A\n"," 29% 72/250 [00:26<01:05,  2.71it/s]\u001b[A\n"," 29% 73/250 [00:26<01:05,  2.71it/s]\u001b[A\n"," 30% 74/250 [00:27<01:04,  2.71it/s]\u001b[A\n"," 30% 75/250 [00:27<01:04,  2.71it/s]\u001b[A\n"," 30% 76/250 [00:27<01:04,  2.71it/s]\u001b[A\n"," 31% 77/250 [00:28<01:03,  2.71it/s]\u001b[A\n"," 31% 78/250 [00:28<01:03,  2.70it/s]\u001b[A\n"," 32% 79/250 [00:28<01:03,  2.70it/s]\u001b[A\n"," 32% 80/250 [00:29<01:02,  2.71it/s]\u001b[A\n"," 32% 81/250 [00:29<01:02,  2.71it/s]\u001b[A\n"," 33% 82/250 [00:29<01:02,  2.71it/s]\u001b[A\n"," 33% 83/250 [00:30<01:01,  2.71it/s]\u001b[A\n"," 34% 84/250 [00:30<01:01,  2.70it/s]\u001b[A\n"," 34% 85/250 [00:31<01:01,  2.69it/s]\u001b[A\n"," 34% 86/250 [00:31<01:01,  2.69it/s]\u001b[A\n"," 35% 87/250 [00:31<01:00,  2.69it/s]\u001b[A\n"," 35% 88/250 [00:32<00:59,  2.70it/s]\u001b[A\n"," 36% 89/250 [00:32<00:59,  2.70it/s]\u001b[A\n"," 36% 90/250 [00:32<00:59,  2.70it/s]\u001b[A\n"," 36% 91/250 [00:33<00:58,  2.70it/s]\u001b[A\n"," 37% 92/250 [00:33<00:58,  2.70it/s]\u001b[A\n"," 37% 93/250 [00:34<00:58,  2.71it/s]\u001b[A\n"," 38% 94/250 [00:34<00:57,  2.71it/s]\u001b[A\n"," 38% 95/250 [00:34<00:57,  2.71it/s]\u001b[A\n"," 38% 96/250 [00:35<00:56,  2.72it/s]\u001b[A\n"," 39% 97/250 [00:35<00:56,  2.72it/s]\u001b[A\n"," 39% 98/250 [00:35<00:55,  2.72it/s]\u001b[A\n"," 40% 99/250 [00:36<00:55,  2.71it/s]\u001b[A\n"," 40% 100/250 [00:36<00:55,  2.71it/s]\u001b[A\n"," 40% 101/250 [00:37<00:54,  2.72it/s]\u001b[A\n"," 41% 102/250 [00:37<00:54,  2.72it/s]\u001b[A\n"," 41% 103/250 [00:37<00:54,  2.72it/s]\u001b[A\n"," 42% 104/250 [00:38<00:53,  2.71it/s]\u001b[A\n"," 42% 105/250 [00:38<00:53,  2.72it/s]\u001b[A\n"," 42% 106/250 [00:38<00:53,  2.72it/s]\u001b[A\n"," 43% 107/250 [00:39<00:52,  2.71it/s]\u001b[A\n"," 43% 108/250 [00:39<00:52,  2.71it/s]\u001b[A\n"," 44% 109/250 [00:39<00:52,  2.70it/s]\u001b[A\n"," 44% 110/250 [00:40<00:51,  2.71it/s]\u001b[A\n"," 44% 111/250 [00:40<00:51,  2.71it/s]\u001b[A\n"," 45% 112/250 [00:41<00:50,  2.71it/s]\u001b[A\n"," 45% 113/250 [00:41<00:50,  2.72it/s]\u001b[A\n"," 46% 114/250 [00:41<00:50,  2.72it/s]\u001b[A\n"," 46% 115/250 [00:42<00:49,  2.71it/s]\u001b[A\n"," 46% 116/250 [00:42<00:49,  2.71it/s]\u001b[A\n"," 47% 117/250 [00:42<00:49,  2.71it/s]\u001b[A\n"," 47% 118/250 [00:43<00:48,  2.71it/s]\u001b[A\n"," 48% 119/250 [00:43<00:48,  2.70it/s]\u001b[A\n"," 48% 120/250 [00:44<00:48,  2.69it/s]\u001b[A\n"," 48% 121/250 [00:44<00:47,  2.70it/s]\u001b[A\n"," 49% 122/250 [00:44<00:47,  2.70it/s]\u001b[A\n"," 49% 123/250 [00:45<00:47,  2.70it/s]\u001b[A\n"," 50% 124/250 [00:45<00:46,  2.69it/s]\u001b[A\n"," 50% 125/250 [00:45<00:46,  2.69it/s]\u001b[A\n"," 50% 126/250 [00:46<00:46,  2.70it/s]\u001b[A\n"," 51% 127/250 [00:46<00:45,  2.70it/s]\u001b[A\n"," 51% 128/250 [00:46<00:45,  2.69it/s]\u001b[A\n"," 52% 129/250 [00:47<00:44,  2.70it/s]\u001b[A\n"," 52% 130/250 [00:47<00:44,  2.70it/s]\u001b[A\n"," 52% 131/250 [00:48<00:43,  2.71it/s]\u001b[A\n"," 53% 132/250 [00:48<00:43,  2.71it/s]\u001b[A\n"," 53% 133/250 [00:48<00:43,  2.71it/s]\u001b[A\n"," 54% 134/250 [00:49<00:42,  2.71it/s]\u001b[A\n"," 54% 135/250 [00:49<00:42,  2.71it/s]\u001b[A\n"," 54% 136/250 [00:49<00:42,  2.71it/s]\u001b[A\n"," 55% 137/250 [00:50<00:41,  2.71it/s]\u001b[A\n"," 55% 138/250 [00:50<00:41,  2.71it/s]\u001b[A\n"," 56% 139/250 [00:51<00:40,  2.71it/s]\u001b[A\n"," 56% 140/250 [00:51<00:40,  2.70it/s]\u001b[A\n"," 56% 141/250 [00:51<00:40,  2.67it/s]\u001b[A\n"," 57% 142/250 [00:52<00:40,  2.68it/s]\u001b[A\n"," 57% 143/250 [00:52<00:39,  2.70it/s]\u001b[A\n"," 58% 144/250 [00:52<00:39,  2.69it/s]\u001b[A\n"," 58% 145/250 [00:53<00:38,  2.70it/s]\u001b[A\n"," 58% 146/250 [00:53<00:38,  2.71it/s]\u001b[A\n"," 59% 147/250 [00:54<00:38,  2.71it/s]\u001b[A\n"," 59% 148/250 [00:54<00:37,  2.70it/s]\u001b[A\n"," 60% 149/250 [00:54<00:37,  2.70it/s]\u001b[A\n"," 60% 150/250 [00:55<00:37,  2.69it/s]\u001b[A\n"," 60% 151/250 [00:55<00:36,  2.70it/s]\u001b[A\n"," 61% 152/250 [00:55<00:36,  2.70it/s]\u001b[A\n"," 61% 153/250 [00:56<00:35,  2.70it/s]\u001b[A\n"," 62% 154/250 [00:56<00:35,  2.71it/s]\u001b[A\n"," 62% 155/250 [00:56<00:35,  2.70it/s]\u001b[A\n"," 62% 156/250 [00:57<00:34,  2.71it/s]\u001b[A\n"," 63% 157/250 [00:57<00:34,  2.71it/s]\u001b[A\n"," 63% 158/250 [00:58<00:34,  2.71it/s]\u001b[A\n"," 64% 159/250 [00:58<00:33,  2.71it/s]\u001b[A\n"," 64% 160/250 [00:58<00:33,  2.68it/s]\u001b[A\n"," 64% 161/250 [00:59<00:33,  2.69it/s]\u001b[A\n"," 65% 162/250 [00:59<00:32,  2.69it/s]\u001b[A\n"," 65% 163/250 [00:59<00:32,  2.69it/s]\u001b[A\n"," 66% 164/250 [01:00<00:31,  2.71it/s]\u001b[A\n"," 66% 165/250 [01:00<00:31,  2.71it/s]\u001b[A\n"," 66% 166/250 [01:01<00:30,  2.72it/s]\u001b[A\n"," 67% 167/250 [01:01<00:30,  2.72it/s]\u001b[A\n"," 67% 168/250 [01:01<00:30,  2.71it/s]\u001b[A\n"," 68% 169/250 [01:02<00:29,  2.71it/s]\u001b[A\n"," 68% 170/250 [01:02<00:29,  2.71it/s]\u001b[A\n"," 68% 171/250 [01:02<00:29,  2.70it/s]\u001b[A\n"," 69% 172/250 [01:03<00:28,  2.70it/s]\u001b[A\n"," 69% 173/250 [01:03<00:28,  2.71it/s]\u001b[A\n"," 70% 174/250 [01:04<00:28,  2.70it/s]\u001b[A\n"," 70% 175/250 [01:04<00:27,  2.71it/s]\u001b[A\n"," 70% 176/250 [01:04<00:27,  2.71it/s]\u001b[A\n"," 71% 177/250 [01:05<00:26,  2.70it/s]\u001b[A\n"," 71% 178/250 [01:05<00:26,  2.71it/s]\u001b[A\n"," 72% 179/250 [01:05<00:26,  2.71it/s]\u001b[A\n"," 72% 180/250 [01:06<00:25,  2.70it/s]\u001b[A\n"," 72% 181/250 [01:06<00:25,  2.70it/s]\u001b[A\n"," 73% 182/250 [01:06<00:25,  2.70it/s]\u001b[A\n"," 73% 183/250 [01:07<00:24,  2.70it/s]\u001b[A\n"," 74% 184/250 [01:07<00:24,  2.70it/s]\u001b[A\n"," 74% 185/250 [01:08<00:24,  2.69it/s]\u001b[A\n"," 74% 186/250 [01:08<00:23,  2.69it/s]\u001b[A\n"," 75% 187/250 [01:08<00:23,  2.69it/s]\u001b[A\n"," 75% 188/250 [01:09<00:23,  2.69it/s]\u001b[A\n"," 76% 189/250 [01:09<00:22,  2.68it/s]\u001b[A\n"," 76% 190/250 [01:09<00:22,  2.67it/s]\u001b[A\n"," 76% 191/250 [01:10<00:22,  2.66it/s]\u001b[A\n"," 77% 192/250 [01:10<00:21,  2.65it/s]\u001b[A\n"," 77% 193/250 [01:11<00:21,  2.62it/s]\u001b[A\n"," 78% 194/250 [01:11<00:21,  2.62it/s]\u001b[A\n"," 78% 195/250 [01:11<00:20,  2.64it/s]\u001b[A\n"," 78% 196/250 [01:12<00:20,  2.66it/s]\u001b[A\n"," 79% 197/250 [01:12<00:19,  2.67it/s]\u001b[A\n"," 79% 198/250 [01:12<00:19,  2.67it/s]\u001b[A\n"," 80% 199/250 [01:13<00:19,  2.67it/s]\u001b[A\n"," 80% 200/250 [01:13<00:18,  2.67it/s]\u001b[A\n"," 80% 201/250 [01:14<00:18,  2.68it/s]\u001b[A\n"," 81% 202/250 [01:14<00:17,  2.68it/s]\u001b[A\n"," 81% 203/250 [01:14<00:17,  2.68it/s]\u001b[A\n"," 82% 204/250 [01:15<00:17,  2.69it/s]\u001b[A\n"," 82% 205/250 [01:15<00:16,  2.70it/s]\u001b[A\n"," 82% 206/250 [01:15<00:16,  2.69it/s]\u001b[A\n"," 83% 207/250 [01:16<00:15,  2.70it/s]\u001b[A\n"," 83% 208/250 [01:16<00:15,  2.70it/s]\u001b[A\n"," 84% 209/250 [01:17<00:15,  2.70it/s]\u001b[A\n"," 84% 210/250 [01:17<00:14,  2.70it/s]\u001b[A\n"," 84% 211/250 [01:17<00:14,  2.70it/s]\u001b[A\n"," 85% 212/250 [01:18<00:14,  2.70it/s]\u001b[A\n"," 85% 213/250 [01:18<00:13,  2.70it/s]\u001b[A\n"," 86% 214/250 [01:18<00:13,  2.71it/s]\u001b[A\n"," 86% 215/250 [01:19<00:12,  2.72it/s]\u001b[A\n"," 86% 216/250 [01:19<00:12,  2.72it/s]\u001b[A\n"," 87% 217/250 [01:20<00:12,  2.70it/s]\u001b[A\n"," 87% 218/250 [01:20<00:11,  2.70it/s]\u001b[A\n"," 88% 219/250 [01:20<00:11,  2.71it/s]\u001b[A\n"," 88% 220/250 [01:21<00:11,  2.70it/s]\u001b[A\n"," 88% 221/250 [01:21<00:10,  2.71it/s]\u001b[A\n"," 89% 222/250 [01:21<00:10,  2.70it/s]\u001b[A\n"," 89% 223/250 [01:22<00:09,  2.71it/s]\u001b[A\n"," 90% 224/250 [01:22<00:09,  2.71it/s]\u001b[A\n"," 90% 225/250 [01:22<00:09,  2.70it/s]\u001b[A\n"," 90% 226/250 [01:23<00:08,  2.70it/s]\u001b[A\n"," 91% 227/250 [01:23<00:08,  2.70it/s]\u001b[A\n"," 91% 228/250 [01:24<00:08,  2.70it/s]\u001b[A\n"," 92% 229/250 [01:24<00:07,  2.70it/s]\u001b[A\n"," 92% 230/250 [01:24<00:07,  2.69it/s]\u001b[A\n"," 92% 231/250 [01:25<00:07,  2.69it/s]\u001b[A\n"," 93% 232/250 [01:25<00:06,  2.70it/s]\u001b[A\n"," 93% 233/250 [01:25<00:06,  2.70it/s]\u001b[A\n"," 94% 234/250 [01:26<00:05,  2.70it/s]\u001b[A\n"," 94% 235/250 [01:26<00:05,  2.69it/s]\u001b[A\n"," 94% 236/250 [01:27<00:05,  2.70it/s]\u001b[A\n"," 95% 237/250 [01:27<00:04,  2.70it/s]\u001b[A\n"," 95% 238/250 [01:27<00:04,  2.70it/s]\u001b[A\n"," 96% 239/250 [01:28<00:04,  2.70it/s]\u001b[A\n"," 96% 240/250 [01:28<00:03,  2.70it/s]\u001b[A\n"," 96% 241/250 [01:28<00:03,  2.69it/s]\u001b[A\n"," 97% 242/250 [01:29<00:02,  2.70it/s]\u001b[A\n"," 97% 243/250 [01:29<00:02,  2.69it/s]\u001b[A\n"," 98% 244/250 [01:30<00:02,  2.69it/s]\u001b[A\n"," 98% 245/250 [01:30<00:01,  2.70it/s]\u001b[A\n"," 98% 246/250 [01:30<00:01,  2.70it/s]\u001b[A\n"," 99% 247/250 [01:31<00:01,  2.71it/s]\u001b[A\n"," 99% 248/250 [01:31<00:00,  2.71it/s]\u001b[A\n","100% 249/250 [01:31<00:00,  2.70it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.5553985834121704, 'eval_runtime': 92.6339, 'eval_samples_per_second': 21.59, 'eval_steps_per_second': 2.699, 'epoch': 1.71}\n"," 34% 200/585 [1:22:22<2:35:27, 24.23s/it]\n","100% 250/250 [01:32<00:00,  2.69it/s]\u001b[A\n","                                     \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","{'loss': 0.5513, 'learning_rate': 3.8762886597938145e-05, 'epoch': 1.79}\n","{'loss': 0.5498, 'learning_rate': 3.7731958762886596e-05, 'epoch': 1.88}\n","{'loss': 0.5501, 'learning_rate': 3.670103092783505e-05, 'epoch': 1.96}\n","{'loss': 0.5465, 'learning_rate': 3.5670103092783505e-05, 'epoch': 2.05}\n","{'loss': 0.5456, 'learning_rate': 3.4639175257731957e-05, 'epoch': 2.13}\n","{'loss': 0.5441, 'learning_rate': 3.3608247422680415e-05, 'epoch': 2.22}\n","{'loss': 0.5436, 'learning_rate': 3.2577319587628866e-05, 'epoch': 2.3}\n","{'loss': 0.5401, 'learning_rate': 3.154639175257732e-05, 'epoch': 2.39}\n","{'loss': 0.5395, 'learning_rate': 3.051546391752578e-05, 'epoch': 2.47}\n","{'loss': 0.5411, 'learning_rate': 2.948453608247423e-05, 'epoch': 2.56}\n","{'loss': 0.5379, 'learning_rate': 2.845360824742268e-05, 'epoch': 2.64}\n","{'loss': 0.5384, 'learning_rate': 2.742268041237114e-05, 'epoch': 2.73}\n","{'loss': 0.5356, 'learning_rate': 2.639175257731959e-05, 'epoch': 2.81}\n","{'loss': 0.5319, 'learning_rate': 2.536082474226804e-05, 'epoch': 2.9}\n","{'loss': 0.5344, 'learning_rate': 2.4329896907216496e-05, 'epoch': 2.99}\n","{'loss': 0.5353, 'learning_rate': 2.329896907216495e-05, 'epoch': 3.07}\n","{'loss': 0.5303, 'learning_rate': 2.2268041237113405e-05, 'epoch': 3.16}\n","{'loss': 0.5313, 'learning_rate': 2.1237113402061857e-05, 'epoch': 3.24}\n","{'loss': 0.5323, 'learning_rate': 2.020618556701031e-05, 'epoch': 3.33}\n","{'loss': 0.5304, 'learning_rate': 1.9175257731958766e-05, 'epoch': 3.41}\n"," 68% 400/585 [2:43:10<1:14:53, 24.29s/it]\n","  0% 0/250 [00:00<?, ?it/s]\u001b[A\n","  1% 2/250 [00:00<00:45,  5.40it/s]\u001b[A\n","  1% 3/250 [00:00<01:05,  3.75it/s]\u001b[A\n","  2% 4/250 [00:01<01:15,  3.26it/s]\u001b[A\n","  2% 5/250 [00:01<01:20,  3.03it/s]\u001b[A\n","  2% 6/250 [00:01<01:24,  2.90it/s]\u001b[A\n","  3% 7/250 [00:02<01:26,  2.82it/s]\u001b[A\n","  3% 8/250 [00:02<01:27,  2.77it/s]\u001b[A\n","  4% 9/250 [00:02<01:27,  2.75it/s]\u001b[A\n","  4% 10/250 [00:03<01:27,  2.73it/s]\u001b[A\n","  4% 11/250 [00:03<01:28,  2.71it/s]\u001b[A\n","  5% 12/250 [00:04<01:27,  2.71it/s]\u001b[A\n","  5% 13/250 [00:04<01:27,  2.70it/s]\u001b[A\n","  6% 14/250 [00:04<01:27,  2.70it/s]\u001b[A\n","  6% 15/250 [00:05<01:27,  2.68it/s]\u001b[A\n","  6% 16/250 [00:05<01:27,  2.68it/s]\u001b[A\n","  7% 17/250 [00:05<01:26,  2.69it/s]\u001b[A\n","  7% 18/250 [00:06<01:26,  2.69it/s]\u001b[A\n","  8% 19/250 [00:06<01:25,  2.69it/s]\u001b[A\n","  8% 20/250 [00:07<01:25,  2.69it/s]\u001b[A\n","  8% 21/250 [00:07<01:25,  2.69it/s]\u001b[A\n","  9% 22/250 [00:07<01:24,  2.69it/s]\u001b[A\n","  9% 23/250 [00:08<01:24,  2.69it/s]\u001b[A\n"," 10% 24/250 [00:08<01:23,  2.70it/s]\u001b[A\n"," 10% 25/250 [00:08<01:23,  2.70it/s]\u001b[A\n"," 10% 26/250 [00:09<01:22,  2.71it/s]\u001b[A\n"," 11% 27/250 [00:09<01:22,  2.72it/s]\u001b[A\n"," 11% 28/250 [00:10<01:21,  2.72it/s]\u001b[A\n"," 12% 29/250 [00:10<01:21,  2.72it/s]\u001b[A\n"," 12% 30/250 [00:10<01:20,  2.72it/s]\u001b[A\n"," 12% 31/250 [00:11<01:20,  2.72it/s]\u001b[A\n"," 13% 32/250 [00:11<01:20,  2.71it/s]\u001b[A\n"," 13% 33/250 [00:11<01:20,  2.71it/s]\u001b[A\n"," 14% 34/250 [00:12<01:20,  2.70it/s]\u001b[A\n"," 14% 35/250 [00:12<01:19,  2.70it/s]\u001b[A\n"," 14% 36/250 [00:13<01:19,  2.70it/s]\u001b[A\n"," 15% 37/250 [00:13<01:18,  2.70it/s]\u001b[A\n"," 15% 38/250 [00:13<01:18,  2.71it/s]\u001b[A\n"," 16% 39/250 [00:14<01:18,  2.70it/s]\u001b[A\n"," 16% 40/250 [00:14<01:17,  2.70it/s]\u001b[A\n"," 16% 41/250 [00:14<01:17,  2.69it/s]\u001b[A\n"," 17% 42/250 [00:15<01:17,  2.68it/s]\u001b[A\n"," 17% 43/250 [00:15<01:17,  2.68it/s]\u001b[A\n"," 18% 44/250 [00:15<01:16,  2.68it/s]\u001b[A\n"," 18% 45/250 [00:16<01:16,  2.67it/s]\u001b[A\n"," 18% 46/250 [00:16<01:16,  2.67it/s]\u001b[A\n"," 19% 47/250 [00:17<01:16,  2.67it/s]\u001b[A\n"," 19% 48/250 [00:17<01:15,  2.67it/s]\u001b[A\n"," 20% 49/250 [00:17<01:15,  2.67it/s]\u001b[A\n"," 20% 50/250 [00:18<01:15,  2.66it/s]\u001b[A\n"," 20% 51/250 [00:18<01:14,  2.66it/s]\u001b[A\n"," 21% 52/250 [00:18<01:14,  2.66it/s]\u001b[A\n"," 21% 53/250 [00:19<01:13,  2.66it/s]\u001b[A\n"," 22% 54/250 [00:19<01:13,  2.67it/s]\u001b[A\n"," 22% 55/250 [00:20<01:13,  2.66it/s]\u001b[A\n"," 22% 56/250 [00:20<01:12,  2.66it/s]\u001b[A\n"," 23% 57/250 [00:20<01:12,  2.66it/s]\u001b[A\n"," 23% 58/250 [00:21<01:12,  2.66it/s]\u001b[A\n"," 24% 59/250 [00:21<01:11,  2.66it/s]\u001b[A\n"," 24% 60/250 [00:21<01:11,  2.65it/s]\u001b[A\n"," 24% 61/250 [00:22<01:11,  2.64it/s]\u001b[A\n"," 25% 62/250 [00:22<01:11,  2.64it/s]\u001b[A\n"," 25% 63/250 [00:23<01:10,  2.65it/s]\u001b[A\n"," 26% 64/250 [00:23<01:10,  2.65it/s]\u001b[A\n"," 26% 65/250 [00:23<01:09,  2.66it/s]\u001b[A\n"," 26% 66/250 [00:24<01:09,  2.65it/s]\u001b[A\n"," 27% 67/250 [00:24<01:08,  2.66it/s]\u001b[A\n"," 27% 68/250 [00:25<01:08,  2.65it/s]\u001b[A\n"," 28% 69/250 [00:25<01:08,  2.65it/s]\u001b[A\n"," 28% 70/250 [00:25<01:07,  2.65it/s]\u001b[A\n"," 28% 71/250 [00:26<01:07,  2.65it/s]\u001b[A\n"," 29% 72/250 [00:26<01:07,  2.65it/s]\u001b[A\n"," 29% 73/250 [00:26<01:06,  2.65it/s]\u001b[A\n"," 30% 74/250 [00:27<01:06,  2.65it/s]\u001b[A\n"," 30% 75/250 [00:27<01:05,  2.65it/s]\u001b[A\n"," 30% 76/250 [00:28<01:05,  2.65it/s]\u001b[A\n"," 31% 77/250 [00:28<01:05,  2.65it/s]\u001b[A\n"," 31% 78/250 [00:28<01:04,  2.65it/s]\u001b[A\n"," 32% 79/250 [00:29<01:04,  2.66it/s]\u001b[A\n"," 32% 80/250 [00:29<01:03,  2.67it/s]\u001b[A\n"," 32% 81/250 [00:29<01:03,  2.67it/s]\u001b[A\n"," 33% 82/250 [00:30<01:03,  2.66it/s]\u001b[A\n"," 33% 83/250 [00:30<01:02,  2.66it/s]\u001b[A\n"," 34% 84/250 [00:31<01:02,  2.66it/s]\u001b[A\n"," 34% 85/250 [00:31<01:01,  2.66it/s]\u001b[A\n"," 34% 86/250 [00:31<01:01,  2.66it/s]\u001b[A\n"," 35% 87/250 [00:32<01:01,  2.66it/s]\u001b[A\n"," 35% 88/250 [00:32<01:00,  2.66it/s]\u001b[A\n"," 36% 89/250 [00:32<01:00,  2.66it/s]\u001b[A\n"," 36% 90/250 [00:33<01:00,  2.66it/s]\u001b[A\n"," 36% 91/250 [00:33<00:59,  2.66it/s]\u001b[A\n"," 37% 92/250 [00:34<00:59,  2.66it/s]\u001b[A\n"," 37% 93/250 [00:34<00:59,  2.66it/s]\u001b[A\n"," 38% 94/250 [00:34<00:58,  2.66it/s]\u001b[A\n"," 38% 95/250 [00:35<00:58,  2.66it/s]\u001b[A\n"," 38% 96/250 [00:35<00:57,  2.67it/s]\u001b[A\n"," 39% 97/250 [00:35<00:57,  2.67it/s]\u001b[A\n"," 39% 98/250 [00:36<00:56,  2.68it/s]\u001b[A\n"," 40% 99/250 [00:36<00:56,  2.68it/s]\u001b[A\n"," 40% 100/250 [00:37<00:56,  2.67it/s]\u001b[A\n"," 40% 101/250 [00:37<00:55,  2.67it/s]\u001b[A\n"," 41% 102/250 [00:37<00:55,  2.66it/s]\u001b[A\n"," 41% 103/250 [00:38<00:55,  2.66it/s]\u001b[A\n"," 42% 104/250 [00:38<00:54,  2.66it/s]\u001b[A\n"," 42% 105/250 [00:38<00:54,  2.66it/s]\u001b[A\n"," 42% 106/250 [00:39<00:54,  2.65it/s]\u001b[A\n"," 43% 107/250 [00:39<00:53,  2.65it/s]\u001b[A\n"," 43% 108/250 [00:40<00:53,  2.65it/s]\u001b[A\n"," 44% 109/250 [00:40<00:53,  2.65it/s]\u001b[A\n"," 44% 110/250 [00:40<00:52,  2.65it/s]\u001b[A\n"," 44% 111/250 [00:41<00:52,  2.65it/s]\u001b[A\n"," 45% 112/250 [00:41<00:51,  2.65it/s]\u001b[A\n"," 45% 113/250 [00:41<00:52,  2.62it/s]\u001b[A\n"," 46% 114/250 [00:42<00:51,  2.64it/s]\u001b[A\n"," 46% 115/250 [00:42<00:51,  2.63it/s]\u001b[A\n"," 46% 116/250 [00:43<00:50,  2.63it/s]\u001b[A\n"," 47% 117/250 [00:43<00:50,  2.64it/s]\u001b[A\n"," 47% 118/250 [00:43<00:50,  2.64it/s]\u001b[A\n"," 48% 119/250 [00:44<00:49,  2.64it/s]\u001b[A\n"," 48% 120/250 [00:44<00:49,  2.65it/s]\u001b[A\n"," 48% 121/250 [00:44<00:49,  2.63it/s]\u001b[A\n"," 49% 122/250 [00:45<00:48,  2.64it/s]\u001b[A\n"," 49% 123/250 [00:45<00:47,  2.65it/s]\u001b[A\n"," 50% 124/250 [00:46<00:47,  2.65it/s]\u001b[A\n"," 50% 125/250 [00:46<00:47,  2.64it/s]\u001b[A\n"," 50% 126/250 [00:46<00:46,  2.64it/s]\u001b[A\n"," 51% 127/250 [00:47<00:46,  2.65it/s]\u001b[A\n"," 51% 128/250 [00:47<00:45,  2.66it/s]\u001b[A\n"," 52% 129/250 [00:47<00:45,  2.66it/s]\u001b[A\n"," 52% 130/250 [00:48<00:45,  2.65it/s]\u001b[A\n"," 52% 131/250 [00:48<00:44,  2.65it/s]\u001b[A\n"," 53% 132/250 [00:49<00:44,  2.65it/s]\u001b[A\n"," 53% 133/250 [00:49<00:43,  2.66it/s]\u001b[A\n"," 54% 134/250 [00:49<00:43,  2.67it/s]\u001b[A\n"," 54% 135/250 [00:50<00:43,  2.66it/s]\u001b[A\n"," 54% 136/250 [00:50<00:42,  2.66it/s]\u001b[A\n"," 55% 137/250 [00:51<00:42,  2.66it/s]\u001b[A\n"," 55% 138/250 [00:51<00:42,  2.66it/s]\u001b[A\n"," 56% 139/250 [00:51<00:41,  2.66it/s]\u001b[A\n"," 56% 140/250 [00:52<00:41,  2.67it/s]\u001b[A\n"," 56% 141/250 [00:52<00:40,  2.67it/s]\u001b[A\n"," 57% 142/250 [00:52<00:40,  2.67it/s]\u001b[A\n"," 57% 143/250 [00:53<00:40,  2.66it/s]\u001b[A\n"," 58% 144/250 [00:53<00:40,  2.65it/s]\u001b[A\n"," 58% 145/250 [00:54<00:39,  2.63it/s]\u001b[A\n"," 58% 146/250 [00:54<00:39,  2.63it/s]\u001b[A\n"," 59% 147/250 [00:54<00:39,  2.63it/s]\u001b[A\n"," 59% 148/250 [00:55<00:38,  2.64it/s]\u001b[A\n"," 60% 149/250 [00:55<00:38,  2.64it/s]\u001b[A\n"," 60% 150/250 [00:55<00:37,  2.63it/s]\u001b[A\n"," 60% 151/250 [00:56<00:37,  2.63it/s]\u001b[A\n"," 61% 152/250 [00:56<00:37,  2.62it/s]\u001b[A\n"," 61% 153/250 [00:57<00:36,  2.64it/s]\u001b[A\n"," 62% 154/250 [00:57<00:36,  2.65it/s]\u001b[A\n"," 62% 155/250 [00:57<00:35,  2.66it/s]\u001b[A\n"," 62% 156/250 [00:58<00:35,  2.66it/s]\u001b[A\n"," 63% 157/250 [00:58<00:34,  2.67it/s]\u001b[A\n"," 63% 158/250 [00:58<00:34,  2.66it/s]\u001b[A\n"," 64% 159/250 [00:59<00:34,  2.65it/s]\u001b[A\n"," 64% 160/250 [00:59<00:33,  2.66it/s]\u001b[A\n"," 64% 161/250 [01:00<00:33,  2.65it/s]\u001b[A\n"," 65% 162/250 [01:00<00:33,  2.65it/s]\u001b[A\n"," 65% 163/250 [01:00<00:32,  2.66it/s]\u001b[A\n"," 66% 164/250 [01:01<00:32,  2.65it/s]\u001b[A\n"," 66% 165/250 [01:01<00:32,  2.65it/s]\u001b[A\n"," 66% 166/250 [01:01<00:31,  2.65it/s]\u001b[A\n"," 67% 167/250 [01:02<00:31,  2.65it/s]\u001b[A\n"," 67% 168/250 [01:02<00:30,  2.65it/s]\u001b[A\n"," 68% 169/250 [01:03<00:30,  2.65it/s]\u001b[A\n"," 68% 170/250 [01:03<00:30,  2.65it/s]\u001b[A\n"," 68% 171/250 [01:03<00:29,  2.65it/s]\u001b[A\n"," 69% 172/250 [01:04<00:29,  2.65it/s]\u001b[A\n"," 69% 173/250 [01:04<00:28,  2.66it/s]\u001b[A\n"," 70% 174/250 [01:04<00:28,  2.67it/s]\u001b[A\n"," 70% 175/250 [01:05<00:28,  2.67it/s]\u001b[A\n"," 70% 176/250 [01:05<00:27,  2.68it/s]\u001b[A\n"," 71% 177/250 [01:06<00:27,  2.69it/s]\u001b[A\n"," 71% 178/250 [01:06<00:26,  2.69it/s]\u001b[A\n"," 72% 179/250 [01:06<00:26,  2.70it/s]\u001b[A\n"," 72% 180/250 [01:07<00:25,  2.71it/s]\u001b[A\n"," 72% 181/250 [01:07<00:25,  2.71it/s]\u001b[A\n"," 73% 182/250 [01:07<00:25,  2.71it/s]\u001b[A\n"," 73% 183/250 [01:08<00:24,  2.71it/s]\u001b[A\n"," 74% 184/250 [01:08<00:24,  2.70it/s]\u001b[A\n"," 74% 185/250 [01:09<00:24,  2.69it/s]\u001b[A\n"," 74% 186/250 [01:09<00:23,  2.69it/s]\u001b[A\n"," 75% 187/250 [01:09<00:23,  2.69it/s]\u001b[A\n"," 75% 188/250 [01:10<00:23,  2.69it/s]\u001b[A\n"," 76% 189/250 [01:10<00:22,  2.70it/s]\u001b[A\n"," 76% 190/250 [01:10<00:22,  2.70it/s]\u001b[A\n"," 76% 191/250 [01:11<00:21,  2.70it/s]\u001b[A\n"," 77% 192/250 [01:11<00:21,  2.71it/s]\u001b[A\n"," 77% 193/250 [01:11<00:21,  2.71it/s]\u001b[A\n"," 78% 194/250 [01:12<00:20,  2.69it/s]\u001b[A\n"," 78% 195/250 [01:12<00:20,  2.68it/s]\u001b[A\n"," 78% 196/250 [01:13<00:20,  2.68it/s]\u001b[A\n"," 79% 197/250 [01:13<00:19,  2.68it/s]\u001b[A\n"," 79% 198/250 [01:13<00:19,  2.68it/s]\u001b[A\n"," 80% 199/250 [01:14<00:19,  2.68it/s]\u001b[A\n"," 80% 200/250 [01:14<00:18,  2.68it/s]\u001b[A\n"," 80% 201/250 [01:14<00:18,  2.67it/s]\u001b[A\n"," 81% 202/250 [01:15<00:17,  2.68it/s]\u001b[A\n"," 81% 203/250 [01:15<00:17,  2.68it/s]\u001b[A\n"," 82% 204/250 [01:16<00:17,  2.68it/s]\u001b[A\n"," 82% 205/250 [01:16<00:16,  2.68it/s]\u001b[A\n"," 82% 206/250 [01:16<00:16,  2.68it/s]\u001b[A\n"," 83% 207/250 [01:17<00:16,  2.68it/s]\u001b[A\n"," 83% 208/250 [01:17<00:15,  2.69it/s]\u001b[A\n"," 84% 209/250 [01:17<00:15,  2.69it/s]\u001b[A\n"," 84% 210/250 [01:18<00:14,  2.69it/s]\u001b[A\n"," 84% 211/250 [01:18<00:14,  2.70it/s]\u001b[A\n"," 85% 212/250 [01:19<00:14,  2.69it/s]\u001b[A\n"," 85% 213/250 [01:19<00:13,  2.70it/s]\u001b[A\n"," 86% 214/250 [01:19<00:13,  2.70it/s]\u001b[A\n"," 86% 215/250 [01:20<00:12,  2.70it/s]\u001b[A\n"," 86% 216/250 [01:20<00:12,  2.70it/s]\u001b[A\n"," 87% 217/250 [01:20<00:12,  2.69it/s]\u001b[A\n"," 87% 218/250 [01:21<00:11,  2.69it/s]\u001b[A\n"," 88% 219/250 [01:21<00:11,  2.68it/s]\u001b[A\n"," 88% 220/250 [01:22<00:11,  2.68it/s]\u001b[A\n"," 88% 221/250 [01:22<00:10,  2.69it/s]\u001b[A\n"," 89% 222/250 [01:22<00:10,  2.69it/s]\u001b[A\n"," 89% 223/250 [01:23<00:10,  2.69it/s]\u001b[A\n"," 90% 224/250 [01:23<00:09,  2.69it/s]\u001b[A\n"," 90% 225/250 [01:23<00:09,  2.69it/s]\u001b[A\n"," 90% 226/250 [01:24<00:08,  2.69it/s]\u001b[A\n"," 91% 227/250 [01:24<00:08,  2.66it/s]\u001b[A\n"," 91% 228/250 [01:25<00:08,  2.67it/s]\u001b[A\n"," 92% 229/250 [01:25<00:07,  2.68it/s]\u001b[A\n"," 92% 230/250 [01:25<00:07,  2.67it/s]\u001b[A\n"," 92% 231/250 [01:26<00:07,  2.67it/s]\u001b[A\n"," 93% 232/250 [01:26<00:06,  2.68it/s]\u001b[A\n"," 93% 233/250 [01:26<00:06,  2.68it/s]\u001b[A\n"," 94% 234/250 [01:27<00:05,  2.68it/s]\u001b[A\n"," 94% 235/250 [01:27<00:05,  2.69it/s]\u001b[A\n"," 94% 236/250 [01:28<00:05,  2.66it/s]\u001b[A\n"," 95% 237/250 [01:28<00:04,  2.68it/s]\u001b[A\n"," 95% 238/250 [01:28<00:04,  2.68it/s]\u001b[A\n"," 96% 239/250 [01:29<00:04,  2.67it/s]\u001b[A\n"," 96% 240/250 [01:29<00:03,  2.68it/s]\u001b[A\n"," 96% 241/250 [01:29<00:03,  2.68it/s]\u001b[A\n"," 97% 242/250 [01:30<00:02,  2.68it/s]\u001b[A\n"," 97% 243/250 [01:30<00:02,  2.68it/s]\u001b[A\n"," 98% 244/250 [01:31<00:02,  2.67it/s]\u001b[A\n"," 98% 245/250 [01:31<00:01,  2.68it/s]\u001b[A\n"," 98% 246/250 [01:31<00:01,  2.68it/s]\u001b[A\n"," 99% 247/250 [01:32<00:01,  2.69it/s]\u001b[A\n"," 99% 248/250 [01:32<00:00,  2.69it/s]\u001b[A\n","100% 249/250 [01:32<00:00,  2.69it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.5335116982460022, 'eval_runtime': 93.6224, 'eval_samples_per_second': 21.362, 'eval_steps_per_second': 2.67, 'epoch': 3.41}\n"," 68% 400/585 [2:44:44<1:14:53, 24.29s/it]\n","100% 250/250 [01:33<00:00,  2.70it/s]\u001b[A\n","                                     \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","{'loss': 0.5289, 'learning_rate': 1.8144329896907217e-05, 'epoch': 3.5}\n","{'loss': 0.5336, 'learning_rate': 1.7113402061855672e-05, 'epoch': 3.58}\n","{'loss': 0.5296, 'learning_rate': 1.6082474226804127e-05, 'epoch': 3.67}\n","{'loss': 0.5321, 'learning_rate': 1.5051546391752578e-05, 'epoch': 3.75}\n","{'loss': 0.5293, 'learning_rate': 1.4020618556701032e-05, 'epoch': 3.84}\n","{'loss': 0.5252, 'learning_rate': 1.2989690721649485e-05, 'epoch': 3.92}\n","{'loss': 0.5242, 'learning_rate': 1.195876288659794e-05, 'epoch': 4.01}\n","{'loss': 0.5271, 'learning_rate': 1.0927835051546393e-05, 'epoch': 4.09}\n","{'loss': 0.5261, 'learning_rate': 9.896907216494846e-06, 'epoch': 4.18}\n","{'loss': 0.5275, 'learning_rate': 8.8659793814433e-06, 'epoch': 4.26}\n","{'loss': 0.5267, 'learning_rate': 7.835051546391754e-06, 'epoch': 4.35}\n","{'loss': 0.5259, 'learning_rate': 6.804123711340206e-06, 'epoch': 4.43}\n","{'loss': 0.5297, 'learning_rate': 5.77319587628866e-06, 'epoch': 4.52}\n","{'loss': 0.5244, 'learning_rate': 4.742268041237113e-06, 'epoch': 4.61}\n","{'loss': 0.5242, 'learning_rate': 3.711340206185567e-06, 'epoch': 4.69}\n","{'loss': 0.5235, 'learning_rate': 2.6804123711340204e-06, 'epoch': 4.78}\n","{'loss': 0.5282, 'learning_rate': 1.6494845360824744e-06, 'epoch': 4.86}\n","{'loss': 0.5246, 'learning_rate': 6.185567010309279e-07, 'epoch': 4.95}\n","100% 585/585 [3:59:39<00:00, 24.32s/it]There were missing keys in the checkpoint model loaded: ['base_model.model.model.embed_tokens.weight', 'base_model.model.model.layers.0.self_attn.q_proj.weight', 'base_model.model.model.layers.0.self_attn.k_proj.weight', 'base_model.model.model.layers.0.self_attn.v_proj.weight', 'base_model.model.model.layers.0.self_attn.o_proj.weight', 'base_model.model.model.layers.0.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.0.mlp.gate_proj.weight', 'base_model.model.model.layers.0.mlp.down_proj.weight', 'base_model.model.model.layers.0.mlp.up_proj.weight', 'base_model.model.model.layers.0.input_layernorm.weight', 'base_model.model.model.layers.0.post_attention_layernorm.weight', 'base_model.model.model.layers.1.self_attn.q_proj.weight', 'base_model.model.model.layers.1.self_attn.k_proj.weight', 'base_model.model.model.layers.1.self_attn.v_proj.weight', 'base_model.model.model.layers.1.self_attn.o_proj.weight', 'base_model.model.model.layers.1.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.1.mlp.gate_proj.weight', 'base_model.model.model.layers.1.mlp.down_proj.weight', 'base_model.model.model.layers.1.mlp.up_proj.weight', 'base_model.model.model.layers.1.input_layernorm.weight', 'base_model.model.model.layers.1.post_attention_layernorm.weight', 'base_model.model.model.layers.2.self_attn.q_proj.weight', 'base_model.model.model.layers.2.self_attn.k_proj.weight', 'base_model.model.model.layers.2.self_attn.v_proj.weight', 'base_model.model.model.layers.2.self_attn.o_proj.weight', 'base_model.model.model.layers.2.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.2.mlp.gate_proj.weight', 'base_model.model.model.layers.2.mlp.down_proj.weight', 'base_model.model.model.layers.2.mlp.up_proj.weight', 'base_model.model.model.layers.2.input_layernorm.weight', 'base_model.model.model.layers.2.post_attention_layernorm.weight', 'base_model.model.model.layers.3.self_attn.q_proj.weight', 'base_model.model.model.layers.3.self_attn.k_proj.weight', 'base_model.model.model.layers.3.self_attn.v_proj.weight', 'base_model.model.model.layers.3.self_attn.o_proj.weight', 'base_model.model.model.layers.3.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.3.mlp.gate_proj.weight', 'base_model.model.model.layers.3.mlp.down_proj.weight', 'base_model.model.model.layers.3.mlp.up_proj.weight', 'base_model.model.model.layers.3.input_layernorm.weight', 'base_model.model.model.layers.3.post_attention_layernorm.weight', 'base_model.model.model.layers.4.self_attn.q_proj.weight', 'base_model.model.model.layers.4.self_attn.k_proj.weight', 'base_model.model.model.layers.4.self_attn.v_proj.weight', 'base_model.model.model.layers.4.self_attn.o_proj.weight', 'base_model.model.model.layers.4.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.4.mlp.gate_proj.weight', 'base_model.model.model.layers.4.mlp.down_proj.weight', 'base_model.model.model.layers.4.mlp.up_proj.weight', 'base_model.model.model.layers.4.input_layernorm.weight', 'base_model.model.model.layers.4.post_attention_layernorm.weight', 'base_model.model.model.layers.5.self_attn.q_proj.weight', 'base_model.model.model.layers.5.self_attn.k_proj.weight', 'base_model.model.model.layers.5.self_attn.v_proj.weight', 'base_model.model.model.layers.5.self_attn.o_proj.weight', 'base_model.model.model.layers.5.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.5.mlp.gate_proj.weight', 'base_model.model.model.layers.5.mlp.down_proj.weight', 'base_model.model.model.layers.5.mlp.up_proj.weight', 'base_model.model.model.layers.5.input_layernorm.weight', 'base_model.model.model.layers.5.post_attention_layernorm.weight', 'base_model.model.model.layers.6.self_attn.q_proj.weight', 'base_model.model.model.layers.6.self_attn.k_proj.weight', 'base_model.model.model.layers.6.self_attn.v_proj.weight', 'base_model.model.model.layers.6.self_attn.o_proj.weight', 'base_model.model.model.layers.6.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.6.mlp.gate_proj.weight', 'base_model.model.model.layers.6.mlp.down_proj.weight', 'base_model.model.model.layers.6.mlp.up_proj.weight', 'base_model.model.model.layers.6.input_layernorm.weight', 'base_model.model.model.layers.6.post_attention_layernorm.weight', 'base_model.model.model.layers.7.self_attn.q_proj.weight', 'base_model.model.model.layers.7.self_attn.k_proj.weight', 'base_model.model.model.layers.7.self_attn.v_proj.weight', 'base_model.model.model.layers.7.self_attn.o_proj.weight', 'base_model.model.model.layers.7.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.7.mlp.gate_proj.weight', 'base_model.model.model.layers.7.mlp.down_proj.weight', 'base_model.model.model.layers.7.mlp.up_proj.weight', 'base_model.model.model.layers.7.input_layernorm.weight', 'base_model.model.model.layers.7.post_attention_layernorm.weight', 'base_model.model.model.layers.8.self_attn.q_proj.weight', 'base_model.model.model.layers.8.self_attn.k_proj.weight', 'base_model.model.model.layers.8.self_attn.v_proj.weight', 'base_model.model.model.layers.8.self_attn.o_proj.weight', 'base_model.model.model.layers.8.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.8.mlp.gate_proj.weight', 'base_model.model.model.layers.8.mlp.down_proj.weight', 'base_model.model.model.layers.8.mlp.up_proj.weight', 'base_model.model.model.layers.8.input_layernorm.weight', 'base_model.model.model.layers.8.post_attention_layernorm.weight', 'base_model.model.model.layers.9.self_attn.q_proj.weight', 'base_model.model.model.layers.9.self_attn.k_proj.weight', 'base_model.model.model.layers.9.self_attn.v_proj.weight', 'base_model.model.model.layers.9.self_attn.o_proj.weight', 'base_model.model.model.layers.9.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.9.mlp.gate_proj.weight', 'base_model.model.model.layers.9.mlp.down_proj.weight', 'base_model.model.model.layers.9.mlp.up_proj.weight', 'base_model.model.model.layers.9.input_layernorm.weight', 'base_model.model.model.layers.9.post_attention_layernorm.weight', 'base_model.model.model.layers.10.self_attn.q_proj.weight', 'base_model.model.model.layers.10.self_attn.k_proj.weight', 'base_model.model.model.layers.10.self_attn.v_proj.weight', 'base_model.model.model.layers.10.self_attn.o_proj.weight', 'base_model.model.model.layers.10.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.10.mlp.gate_proj.weight', 'base_model.model.model.layers.10.mlp.down_proj.weight', 'base_model.model.model.layers.10.mlp.up_proj.weight', 'base_model.model.model.layers.10.input_layernorm.weight', 'base_model.model.model.layers.10.post_attention_layernorm.weight', 'base_model.model.model.layers.11.self_attn.q_proj.weight', 'base_model.model.model.layers.11.self_attn.k_proj.weight', 'base_model.model.model.layers.11.self_attn.v_proj.weight', 'base_model.model.model.layers.11.self_attn.o_proj.weight', 'base_model.model.model.layers.11.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.11.mlp.gate_proj.weight', 'base_model.model.model.layers.11.mlp.down_proj.weight', 'base_model.model.model.layers.11.mlp.up_proj.weight', 'base_model.model.model.layers.11.input_layernorm.weight', 'base_model.model.model.layers.11.post_attention_layernorm.weight', 'base_model.model.model.layers.12.self_attn.q_proj.weight', 'base_model.model.model.layers.12.self_attn.k_proj.weight', 'base_model.model.model.layers.12.self_attn.v_proj.weight', 'base_model.model.model.layers.12.self_attn.o_proj.weight', 'base_model.model.model.layers.12.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.12.mlp.gate_proj.weight', 'base_model.model.model.layers.12.mlp.down_proj.weight', 'base_model.model.model.layers.12.mlp.up_proj.weight', 'base_model.model.model.layers.12.input_layernorm.weight', 'base_model.model.model.layers.12.post_attention_layernorm.weight', 'base_model.model.model.layers.13.self_attn.q_proj.weight', 'base_model.model.model.layers.13.self_attn.k_proj.weight', 'base_model.model.model.layers.13.self_attn.v_proj.weight', 'base_model.model.model.layers.13.self_attn.o_proj.weight', 'base_model.model.model.layers.13.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.13.mlp.gate_proj.weight', 'base_model.model.model.layers.13.mlp.down_proj.weight', 'base_model.model.model.layers.13.mlp.up_proj.weight', 'base_model.model.model.layers.13.input_layernorm.weight', 'base_model.model.model.layers.13.post_attention_layernorm.weight', 'base_model.model.model.layers.14.self_attn.q_proj.weight', 'base_model.model.model.layers.14.self_attn.k_proj.weight', 'base_model.model.model.layers.14.self_attn.v_proj.weight', 'base_model.model.model.layers.14.self_attn.o_proj.weight', 'base_model.model.model.layers.14.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.14.mlp.gate_proj.weight', 'base_model.model.model.layers.14.mlp.down_proj.weight', 'base_model.model.model.layers.14.mlp.up_proj.weight', 'base_model.model.model.layers.14.input_layernorm.weight', 'base_model.model.model.layers.14.post_attention_layernorm.weight', 'base_model.model.model.layers.15.self_attn.q_proj.weight', 'base_model.model.model.layers.15.self_attn.k_proj.weight', 'base_model.model.model.layers.15.self_attn.v_proj.weight', 'base_model.model.model.layers.15.self_attn.o_proj.weight', 'base_model.model.model.layers.15.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.15.mlp.gate_proj.weight', 'base_model.model.model.layers.15.mlp.down_proj.weight', 'base_model.model.model.layers.15.mlp.up_proj.weight', 'base_model.model.model.layers.15.input_layernorm.weight', 'base_model.model.model.layers.15.post_attention_layernorm.weight', 'base_model.model.model.layers.16.self_attn.q_proj.weight', 'base_model.model.model.layers.16.self_attn.k_proj.weight', 'base_model.model.model.layers.16.self_attn.v_proj.weight', 'base_model.model.model.layers.16.self_attn.o_proj.weight', 'base_model.model.model.layers.16.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.16.mlp.gate_proj.weight', 'base_model.model.model.layers.16.mlp.down_proj.weight', 'base_model.model.model.layers.16.mlp.up_proj.weight', 'base_model.model.model.layers.16.input_layernorm.weight', 'base_model.model.model.layers.16.post_attention_layernorm.weight', 'base_model.model.model.layers.17.self_attn.q_proj.weight', 'base_model.model.model.layers.17.self_attn.k_proj.weight', 'base_model.model.model.layers.17.self_attn.v_proj.weight', 'base_model.model.model.layers.17.self_attn.o_proj.weight', 'base_model.model.model.layers.17.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.17.mlp.gate_proj.weight', 'base_model.model.model.layers.17.mlp.down_proj.weight', 'base_model.model.model.layers.17.mlp.up_proj.weight', 'base_model.model.model.layers.17.input_layernorm.weight', 'base_model.model.model.layers.17.post_attention_layernorm.weight', 'base_model.model.model.layers.18.self_attn.q_proj.weight', 'base_model.model.model.layers.18.self_attn.k_proj.weight', 'base_model.model.model.layers.18.self_attn.v_proj.weight', 'base_model.model.model.layers.18.self_attn.o_proj.weight', 'base_model.model.model.layers.18.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.18.mlp.gate_proj.weight', 'base_model.model.model.layers.18.mlp.down_proj.weight', 'base_model.model.model.layers.18.mlp.up_proj.weight', 'base_model.model.model.layers.18.input_layernorm.weight', 'base_model.model.model.layers.18.post_attention_layernorm.weight', 'base_model.model.model.layers.19.self_attn.q_proj.weight', 'base_model.model.model.layers.19.self_attn.k_proj.weight', 'base_model.model.model.layers.19.self_attn.v_proj.weight', 'base_model.model.model.layers.19.self_attn.o_proj.weight', 'base_model.model.model.layers.19.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.19.mlp.gate_proj.weight', 'base_model.model.model.layers.19.mlp.down_proj.weight', 'base_model.model.model.layers.19.mlp.up_proj.weight', 'base_model.model.model.layers.19.input_layernorm.weight', 'base_model.model.model.layers.19.post_attention_layernorm.weight', 'base_model.model.model.layers.20.self_attn.q_proj.weight', 'base_model.model.model.layers.20.self_attn.k_proj.weight', 'base_model.model.model.layers.20.self_attn.v_proj.weight', 'base_model.model.model.layers.20.self_attn.o_proj.weight', 'base_model.model.model.layers.20.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.20.mlp.gate_proj.weight', 'base_model.model.model.layers.20.mlp.down_proj.weight', 'base_model.model.model.layers.20.mlp.up_proj.weight', 'base_model.model.model.layers.20.input_layernorm.weight', 'base_model.model.model.layers.20.post_attention_layernorm.weight', 'base_model.model.model.layers.21.self_attn.q_proj.weight', 'base_model.model.model.layers.21.self_attn.k_proj.weight', 'base_model.model.model.layers.21.self_attn.v_proj.weight', 'base_model.model.model.layers.21.self_attn.o_proj.weight', 'base_model.model.model.layers.21.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.21.mlp.gate_proj.weight', 'base_model.model.model.layers.21.mlp.down_proj.weight', 'base_model.model.model.layers.21.mlp.up_proj.weight', 'base_model.model.model.layers.21.input_layernorm.weight', 'base_model.model.model.layers.21.post_attention_layernorm.weight', 'base_model.model.model.layers.22.self_attn.q_proj.weight', 'base_model.model.model.layers.22.self_attn.k_proj.weight', 'base_model.model.model.layers.22.self_attn.v_proj.weight', 'base_model.model.model.layers.22.self_attn.o_proj.weight', 'base_model.model.model.layers.22.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.22.mlp.gate_proj.weight', 'base_model.model.model.layers.22.mlp.down_proj.weight', 'base_model.model.model.layers.22.mlp.up_proj.weight', 'base_model.model.model.layers.22.input_layernorm.weight', 'base_model.model.model.layers.22.post_attention_layernorm.weight', 'base_model.model.model.layers.23.self_attn.q_proj.weight', 'base_model.model.model.layers.23.self_attn.k_proj.weight', 'base_model.model.model.layers.23.self_attn.v_proj.weight', 'base_model.model.model.layers.23.self_attn.o_proj.weight', 'base_model.model.model.layers.23.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.23.mlp.gate_proj.weight', 'base_model.model.model.layers.23.mlp.down_proj.weight', 'base_model.model.model.layers.23.mlp.up_proj.weight', 'base_model.model.model.layers.23.input_layernorm.weight', 'base_model.model.model.layers.23.post_attention_layernorm.weight', 'base_model.model.model.layers.24.self_attn.q_proj.weight', 'base_model.model.model.layers.24.self_attn.k_proj.weight', 'base_model.model.model.layers.24.self_attn.v_proj.weight', 'base_model.model.model.layers.24.self_attn.o_proj.weight', 'base_model.model.model.layers.24.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.24.mlp.gate_proj.weight', 'base_model.model.model.layers.24.mlp.down_proj.weight', 'base_model.model.model.layers.24.mlp.up_proj.weight', 'base_model.model.model.layers.24.input_layernorm.weight', 'base_model.model.model.layers.24.post_attention_layernorm.weight', 'base_model.model.model.layers.25.self_attn.q_proj.weight', 'base_model.model.model.layers.25.self_attn.k_proj.weight', 'base_model.model.model.layers.25.self_attn.v_proj.weight', 'base_model.model.model.layers.25.self_attn.o_proj.weight', 'base_model.model.model.layers.25.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.25.mlp.gate_proj.weight', 'base_model.model.model.layers.25.mlp.down_proj.weight', 'base_model.model.model.layers.25.mlp.up_proj.weight', 'base_model.model.model.layers.25.input_layernorm.weight', 'base_model.model.model.layers.25.post_attention_layernorm.weight', 'base_model.model.model.layers.26.self_attn.q_proj.weight', 'base_model.model.model.layers.26.self_attn.k_proj.weight', 'base_model.model.model.layers.26.self_attn.v_proj.weight', 'base_model.model.model.layers.26.self_attn.o_proj.weight', 'base_model.model.model.layers.26.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.26.mlp.gate_proj.weight', 'base_model.model.model.layers.26.mlp.down_proj.weight', 'base_model.model.model.layers.26.mlp.up_proj.weight', 'base_model.model.model.layers.26.input_layernorm.weight', 'base_model.model.model.layers.26.post_attention_layernorm.weight', 'base_model.model.model.layers.27.self_attn.q_proj.weight', 'base_model.model.model.layers.27.self_attn.k_proj.weight', 'base_model.model.model.layers.27.self_attn.v_proj.weight', 'base_model.model.model.layers.27.self_attn.o_proj.weight', 'base_model.model.model.layers.27.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.27.mlp.gate_proj.weight', 'base_model.model.model.layers.27.mlp.down_proj.weight', 'base_model.model.model.layers.27.mlp.up_proj.weight', 'base_model.model.model.layers.27.input_layernorm.weight', 'base_model.model.model.layers.27.post_attention_layernorm.weight', 'base_model.model.model.layers.28.self_attn.q_proj.weight', 'base_model.model.model.layers.28.self_attn.k_proj.weight', 'base_model.model.model.layers.28.self_attn.v_proj.weight', 'base_model.model.model.layers.28.self_attn.o_proj.weight', 'base_model.model.model.layers.28.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.28.mlp.gate_proj.weight', 'base_model.model.model.layers.28.mlp.down_proj.weight', 'base_model.model.model.layers.28.mlp.up_proj.weight', 'base_model.model.model.layers.28.input_layernorm.weight', 'base_model.model.model.layers.28.post_attention_layernorm.weight', 'base_model.model.model.layers.29.self_attn.q_proj.weight', 'base_model.model.model.layers.29.self_attn.k_proj.weight', 'base_model.model.model.layers.29.self_attn.v_proj.weight', 'base_model.model.model.layers.29.self_attn.o_proj.weight', 'base_model.model.model.layers.29.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.29.mlp.gate_proj.weight', 'base_model.model.model.layers.29.mlp.down_proj.weight', 'base_model.model.model.layers.29.mlp.up_proj.weight', 'base_model.model.model.layers.29.input_layernorm.weight', 'base_model.model.model.layers.29.post_attention_layernorm.weight', 'base_model.model.model.layers.30.self_attn.q_proj.weight', 'base_model.model.model.layers.30.self_attn.k_proj.weight', 'base_model.model.model.layers.30.self_attn.v_proj.weight', 'base_model.model.model.layers.30.self_attn.o_proj.weight', 'base_model.model.model.layers.30.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.30.mlp.gate_proj.weight', 'base_model.model.model.layers.30.mlp.down_proj.weight', 'base_model.model.model.layers.30.mlp.up_proj.weight', 'base_model.model.model.layers.30.input_layernorm.weight', 'base_model.model.model.layers.30.post_attention_layernorm.weight', 'base_model.model.model.layers.31.self_attn.q_proj.weight', 'base_model.model.model.layers.31.self_attn.k_proj.weight', 'base_model.model.model.layers.31.self_attn.v_proj.weight', 'base_model.model.model.layers.31.self_attn.o_proj.weight', 'base_model.model.model.layers.31.self_attn.rotary_emb.inv_freq', 'base_model.model.model.layers.31.mlp.gate_proj.weight', 'base_model.model.model.layers.31.mlp.down_proj.weight', 'base_model.model.model.layers.31.mlp.up_proj.weight', 'base_model.model.model.layers.31.input_layernorm.weight', 'base_model.model.model.layers.31.post_attention_layernorm.weight', 'base_model.model.model.norm.weight', 'base_model.model.lm_head.0.weight'].\n","{'train_runtime': 14379.94, 'train_samples_per_second': 10.429, 'train_steps_per_second': 0.041, 'train_loss': 0.6893542575021075, 'epoch': 4.99}\n","100% 585/585 [3:59:39<00:00, 24.58s/it]\n","\n"," If there's a warning about missing keys above, please disregard :)\n"]}],"source":["!python finetune.py \\\n","        --base_model 'baffo32/decapoda-research-llama-7B-hf' \\\n","        --data_path '/content/drive/MyDrive/LLM project/0.프로젝트4_마지막프로젝트_240226/BERT_Training/custom_data.json' \\\n","        --output_dir './output' \\\n","        --num_epochs 5 \\\n","        --learning_rate 5e-5 \\\n","        --val_set_size 2000 \\\n","        --batch_size 256 \\\n","        --micro_batch_size 64 \\\n","        --prompt_template_name 'custom'"]},{"cell_type":"code","source":["!mkdir /content/drive/MyDrive/LLaMa-Alpaca-LoRA\n","!cp -a output /content/drive/MyDrive/LLaMa-Alpaca-LoRA"],"metadata":{"id":"o4R_436aM4tn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mHu7NyrkPtua"},"source":["## Test on Gradio\n","\n","--load_8bit"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ygvnTjfjKWwi","outputId":"785220f5-a6cc-4744-a151-d6999e6073bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["tokenizer.model: 100% 500k/500k [00:00<00:00, 29.4MB/s]\n","special_tokens_map.json: 100% 2.00/2.00 [00:00<00:00, 12.1kB/s]\n","tokenizer_config.json: 100% 142/142 [00:00<00:00, 823kB/s]\n","config.json: 100% 428/428 [00:00<00:00, 2.26MB/s]\n","pytorch_model.bin.index.json: 100% 25.5k/25.5k [00:00<00:00, 65.2MB/s]\n","Downloading shards:   0% 0/33 [00:00<?, ?it/s]\n","pytorch_model-00001-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00001-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 334MB/s]\u001b[A\n","pytorch_model-00001-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 355MB/s]\u001b[A\n","pytorch_model-00001-of-00033.bin:  31% 126M/405M [00:00<00:00, 365MB/s] \u001b[A\n","pytorch_model-00001-of-00033.bin:  41% 168M/405M [00:00<00:00, 373MB/s]\u001b[A\n","pytorch_model-00001-of-00033.bin:  52% 210M/405M [00:00<00:00, 373MB/s]\u001b[A\n","pytorch_model-00001-of-00033.bin:  62% 252M/405M [00:00<00:00, 372MB/s]\u001b[A\n","pytorch_model-00001-of-00033.bin:  73% 294M/405M [00:00<00:00, 373MB/s]\u001b[A\n","pytorch_model-00001-of-00033.bin:  83% 336M/405M [00:00<00:00, 377MB/s]\u001b[A\n","pytorch_model-00001-of-00033.bin: 100% 405M/405M [00:01<00:00, 372MB/s]\n","Downloading shards:   3% 1/33 [00:01<00:38,  1.22s/it]\n","pytorch_model-00002-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00002-of-00033.bin:  10% 41.9M/405M [00:00<00:00, 371MB/s]\u001b[A\n","pytorch_model-00002-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 385MB/s]\u001b[A\n","pytorch_model-00002-of-00033.bin:  31% 126M/405M [00:00<00:00, 379MB/s] \u001b[A\n","pytorch_model-00002-of-00033.bin:  41% 168M/405M [00:00<00:00, 376MB/s]\u001b[A\n","pytorch_model-00002-of-00033.bin:  52% 210M/405M [00:00<00:00, 379MB/s]\u001b[A\n","pytorch_model-00002-of-00033.bin:  62% 252M/405M [00:00<00:00, 380MB/s]\u001b[A\n","pytorch_model-00002-of-00033.bin:  73% 294M/405M [00:00<00:00, 382MB/s]\u001b[A\n","pytorch_model-00002-of-00033.bin:  83% 336M/405M [00:00<00:00, 372MB/s]\u001b[A\n","pytorch_model-00002-of-00033.bin: 100% 405M/405M [00:01<00:00, 365MB/s]\n","Downloading shards:   6% 2/33 [00:02<00:45,  1.47s/it]\n","pytorch_model-00003-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00003-of-00033.bin:  10% 41.9M/405M [00:00<00:00, 369MB/s]\u001b[A\n","pytorch_model-00003-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 385MB/s]\u001b[A\n","pytorch_model-00003-of-00033.bin:  31% 126M/405M [00:00<00:00, 390MB/s] \u001b[A\n","pytorch_model-00003-of-00033.bin:  41% 168M/405M [00:00<00:00, 393MB/s]\u001b[A\n","pytorch_model-00003-of-00033.bin:  52% 210M/405M [00:00<00:00, 389MB/s]\u001b[A\n","pytorch_model-00003-of-00033.bin:  62% 252M/405M [00:00<00:00, 379MB/s]\u001b[A\n","pytorch_model-00003-of-00033.bin:  73% 294M/405M [00:00<00:00, 378MB/s]\u001b[A\n","pytorch_model-00003-of-00033.bin:  83% 336M/405M [00:00<00:00, 377MB/s]\u001b[A\n","pytorch_model-00003-of-00033.bin: 100% 405M/405M [00:01<00:00, 381MB/s]\n","Downloading shards:   9% 3/33 [00:04<00:46,  1.54s/it]\n","pytorch_model-00004-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00004-of-00033.bin:  10% 41.9M/405M [00:00<00:00, 368MB/s]\u001b[A\n","pytorch_model-00004-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 370MB/s]\u001b[A\n","pytorch_model-00004-of-00033.bin:  31% 126M/405M [00:00<00:00, 375MB/s] \u001b[A\n","pytorch_model-00004-of-00033.bin:  41% 168M/405M [00:00<00:00, 380MB/s]\u001b[A\n","pytorch_model-00004-of-00033.bin:  52% 210M/405M [00:00<00:00, 381MB/s]\u001b[A\n","pytorch_model-00004-of-00033.bin:  62% 252M/405M [00:00<00:00, 378MB/s]\u001b[A\n","pytorch_model-00004-of-00033.bin:  73% 294M/405M [00:00<00:00, 373MB/s]\u001b[A\n","pytorch_model-00004-of-00033.bin:  83% 336M/405M [00:00<00:00, 376MB/s]\u001b[A\n","pytorch_model-00004-of-00033.bin: 100% 405M/405M [00:01<00:00, 377MB/s]\n","Downloading shards:  12% 4/33 [00:05<00:40,  1.41s/it]\n","pytorch_model-00005-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00005-of-00033.bin:   5% 21.0M/405M [00:00<00:01, 201MB/s]\u001b[A\n","pytorch_model-00005-of-00033.bin:  13% 52.4M/405M [00:00<00:01, 225MB/s]\u001b[A\n","pytorch_model-00005-of-00033.bin:  21% 83.9M/405M [00:00<00:01, 255MB/s]\u001b[A\n","pytorch_model-00005-of-00033.bin:  28% 115M/405M [00:00<00:01, 270MB/s] \u001b[A\n","pytorch_model-00005-of-00033.bin:  39% 157M/405M [00:00<00:00, 298MB/s]\u001b[A\n","pytorch_model-00005-of-00033.bin:  49% 199M/405M [00:00<00:00, 324MB/s]\u001b[A\n","pytorch_model-00005-of-00033.bin:  60% 241M/405M [00:00<00:00, 342MB/s]\u001b[A\n","pytorch_model-00005-of-00033.bin:  70% 283M/405M [00:00<00:00, 346MB/s]\u001b[A\n","pytorch_model-00005-of-00033.bin:  80% 325M/405M [00:01<00:00, 336MB/s]\u001b[A\n","pytorch_model-00005-of-00033.bin:  91% 367M/405M [00:01<00:00, 342MB/s]\u001b[A\n","pytorch_model-00005-of-00033.bin: 100% 405M/405M [00:01<00:00, 311MB/s]\n","Downloading shards:  15% 5/33 [00:07<00:40,  1.46s/it]\n","pytorch_model-00006-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00006-of-00033.bin:   3% 10.5M/405M [00:00<00:03, 103MB/s]\u001b[A\n","pytorch_model-00006-of-00033.bin:   8% 31.5M/405M [00:00<00:02, 160MB/s]\u001b[A\n","pytorch_model-00006-of-00033.bin:  16% 62.9M/405M [00:00<00:01, 202MB/s]\u001b[A\n","pytorch_model-00006-of-00033.bin:  23% 94.4M/405M [00:00<00:01, 236MB/s]\u001b[A\n","pytorch_model-00006-of-00033.bin:  34% 136M/405M [00:00<00:00, 275MB/s] \u001b[A\n","pytorch_model-00006-of-00033.bin:  44% 178M/405M [00:00<00:00, 301MB/s]\u001b[A\n","pytorch_model-00006-of-00033.bin:  54% 220M/405M [00:00<00:00, 322MB/s]\u001b[A\n","pytorch_model-00006-of-00033.bin:  65% 262M/405M [00:00<00:00, 327MB/s]\u001b[A\n","pytorch_model-00006-of-00033.bin:  75% 304M/405M [00:01<00:00, 312MB/s]\u001b[A\n","pytorch_model-00006-of-00033.bin:  85% 346M/405M [00:01<00:00, 326MB/s]\u001b[A\n","pytorch_model-00006-of-00033.bin: 100% 405M/405M [00:01<00:00, 299MB/s]\n","Downloading shards:  18% 6/33 [00:08<00:39,  1.47s/it]\n","pytorch_model-00007-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00007-of-00033.bin:  10% 41.9M/405M [00:00<00:00, 380MB/s]\u001b[A\n","pytorch_model-00007-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 380MB/s]\u001b[A\n","pytorch_model-00007-of-00033.bin:  31% 126M/405M [00:00<00:00, 389MB/s] \u001b[A\n","pytorch_model-00007-of-00033.bin:  41% 168M/405M [00:00<00:00, 399MB/s]\u001b[A\n","pytorch_model-00007-of-00033.bin:  52% 210M/405M [00:00<00:00, 395MB/s]\u001b[A\n","pytorch_model-00007-of-00033.bin:  62% 252M/405M [00:00<00:00, 380MB/s]\u001b[A\n","pytorch_model-00007-of-00033.bin:  73% 294M/405M [00:00<00:00, 378MB/s]\u001b[A\n","pytorch_model-00007-of-00033.bin:  83% 336M/405M [00:00<00:00, 382MB/s]\u001b[A\n","pytorch_model-00007-of-00033.bin: 100% 405M/405M [00:01<00:00, 384MB/s]\n","Downloading shards:  21% 7/33 [00:09<00:35,  1.38s/it]\n","pytorch_model-00008-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00008-of-00033.bin:  10% 41.9M/405M [00:00<00:00, 374MB/s]\u001b[A\n","pytorch_model-00008-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 391MB/s]\u001b[A\n","pytorch_model-00008-of-00033.bin:  31% 126M/405M [00:00<00:00, 396MB/s] \u001b[A\n","pytorch_model-00008-of-00033.bin:  41% 168M/405M [00:00<00:00, 340MB/s]\u001b[A\n","pytorch_model-00008-of-00033.bin:  52% 210M/405M [00:00<00:00, 311MB/s]\u001b[A\n","pytorch_model-00008-of-00033.bin:  62% 252M/405M [00:00<00:00, 290MB/s]\u001b[A\n","pytorch_model-00008-of-00033.bin:  70% 283M/405M [00:00<00:00, 285MB/s]\u001b[A\n","pytorch_model-00008-of-00033.bin:  78% 315M/405M [00:01<00:00, 286MB/s]\u001b[A\n","pytorch_model-00008-of-00033.bin:  88% 357M/405M [00:01<00:00, 301MB/s]\u001b[A\n","pytorch_model-00008-of-00033.bin: 100% 405M/405M [00:01<00:00, 302MB/s]\n","Downloading shards:  24% 8/33 [00:11<00:35,  1.41s/it]\n","pytorch_model-00009-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00009-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 348MB/s]\u001b[A\n","pytorch_model-00009-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 339MB/s]\u001b[A\n","pytorch_model-00009-of-00033.bin:  31% 126M/405M [00:00<00:00, 338MB/s] \u001b[A\n","pytorch_model-00009-of-00033.bin:  41% 168M/405M [00:00<00:00, 330MB/s]\u001b[A\n","pytorch_model-00009-of-00033.bin:  52% 210M/405M [00:00<00:00, 328MB/s]\u001b[A\n","pytorch_model-00009-of-00033.bin:  62% 252M/405M [00:00<00:00, 342MB/s]\u001b[A\n","pytorch_model-00009-of-00033.bin:  73% 294M/405M [00:00<00:00, 348MB/s]\u001b[A\n","pytorch_model-00009-of-00033.bin:  83% 336M/405M [00:00<00:00, 342MB/s]\u001b[A\n","pytorch_model-00009-of-00033.bin: 100% 405M/405M [00:01<00:00, 338MB/s]\n","Downloading shards:  27% 9/33 [00:12<00:33,  1.38s/it]\n","pytorch_model-00010-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00010-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 355MB/s]\u001b[A\n","pytorch_model-00010-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 334MB/s]\u001b[A\n","pytorch_model-00010-of-00033.bin:  31% 126M/405M [00:00<00:00, 347MB/s] \u001b[A\n","pytorch_model-00010-of-00033.bin:  41% 168M/405M [00:00<00:00, 340MB/s]\u001b[A\n","pytorch_model-00010-of-00033.bin:  52% 210M/405M [00:00<00:00, 326MB/s]\u001b[A\n","pytorch_model-00010-of-00033.bin:  62% 252M/405M [00:00<00:00, 333MB/s]\u001b[A\n","pytorch_model-00010-of-00033.bin:  73% 294M/405M [00:00<00:00, 350MB/s]\u001b[A\n","pytorch_model-00010-of-00033.bin:  83% 336M/405M [00:00<00:00, 359MB/s]\u001b[A\n","pytorch_model-00010-of-00033.bin: 100% 405M/405M [00:01<00:00, 353MB/s]\n","Downloading shards:  30% 10/33 [00:13<00:31,  1.35s/it]\n","pytorch_model-00011-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00011-of-00033.bin:  10% 41.9M/405M [00:00<00:00, 389MB/s]\u001b[A\n","pytorch_model-00011-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 384MB/s]\u001b[A\n","pytorch_model-00011-of-00033.bin:  31% 126M/405M [00:00<00:00, 381MB/s] \u001b[A\n","pytorch_model-00011-of-00033.bin:  41% 168M/405M [00:00<00:00, 373MB/s]\u001b[A\n","pytorch_model-00011-of-00033.bin:  52% 210M/405M [00:00<00:00, 377MB/s]\u001b[A\n","pytorch_model-00011-of-00033.bin:  62% 252M/405M [00:00<00:00, 383MB/s]\u001b[A\n","pytorch_model-00011-of-00033.bin:  73% 294M/405M [00:00<00:00, 385MB/s]\u001b[A\n","pytorch_model-00011-of-00033.bin:  83% 336M/405M [00:00<00:00, 384MB/s]\u001b[A\n","pytorch_model-00011-of-00033.bin: 100% 405M/405M [00:01<00:00, 379MB/s]\n","Downloading shards:  33% 11/33 [00:15<00:31,  1.43s/it]\n","pytorch_model-00012-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00012-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 356MB/s]\u001b[A\n","pytorch_model-00012-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 344MB/s]\u001b[A\n","pytorch_model-00012-of-00033.bin:  31% 126M/405M [00:00<00:00, 342MB/s] \u001b[A\n","pytorch_model-00012-of-00033.bin:  41% 168M/405M [00:00<00:00, 364MB/s]\u001b[A\n","pytorch_model-00012-of-00033.bin:  52% 210M/405M [00:00<00:00, 370MB/s]\u001b[A\n","pytorch_model-00012-of-00033.bin:  62% 252M/405M [00:00<00:00, 375MB/s]\u001b[A\n","pytorch_model-00012-of-00033.bin:  73% 294M/405M [00:00<00:00, 376MB/s]\u001b[A\n","pytorch_model-00012-of-00033.bin:  83% 336M/405M [00:00<00:00, 378MB/s]\u001b[A\n","pytorch_model-00012-of-00033.bin: 100% 405M/405M [00:01<00:00, 368MB/s]\n","Downloading shards:  36% 12/33 [00:16<00:28,  1.37s/it]\n","pytorch_model-00013-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00013-of-00033.bin:  10% 41.9M/405M [00:00<00:00, 375MB/s]\u001b[A\n","pytorch_model-00013-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 380MB/s]\u001b[A\n","pytorch_model-00013-of-00033.bin:  31% 126M/405M [00:00<00:00, 378MB/s] \u001b[A\n","pytorch_model-00013-of-00033.bin:  41% 168M/405M [00:00<00:00, 367MB/s]\u001b[A\n","pytorch_model-00013-of-00033.bin:  52% 210M/405M [00:00<00:00, 375MB/s]\u001b[A\n","pytorch_model-00013-of-00033.bin:  62% 252M/405M [00:00<00:00, 379MB/s]\u001b[A\n","pytorch_model-00013-of-00033.bin:  73% 294M/405M [00:00<00:00, 379MB/s]\u001b[A\n","pytorch_model-00013-of-00033.bin:  83% 336M/405M [00:00<00:00, 371MB/s]\u001b[A\n","pytorch_model-00013-of-00033.bin: 100% 405M/405M [00:01<00:00, 362MB/s]\n","Downloading shards:  39% 13/33 [00:18<00:29,  1.46s/it]\n","pytorch_model-00014-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00014-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 356MB/s]\u001b[A\n","pytorch_model-00014-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 360MB/s]\u001b[A\n","pytorch_model-00014-of-00033.bin:  31% 126M/405M [00:00<00:00, 363MB/s] \u001b[A\n","pytorch_model-00014-of-00033.bin:  41% 168M/405M [00:00<00:00, 368MB/s]\u001b[A\n","pytorch_model-00014-of-00033.bin:  52% 210M/405M [00:00<00:00, 368MB/s]\u001b[A\n","pytorch_model-00014-of-00033.bin:  62% 252M/405M [00:00<00:00, 372MB/s]\u001b[A\n","pytorch_model-00014-of-00033.bin:  73% 294M/405M [00:00<00:00, 371MB/s]\u001b[A\n","pytorch_model-00014-of-00033.bin:  83% 336M/405M [00:00<00:00, 376MB/s]\u001b[A\n","pytorch_model-00014-of-00033.bin: 100% 405M/405M [00:01<00:00, 367MB/s]\n","Downloading shards:  42% 14/33 [00:19<00:26,  1.39s/it]\n","pytorch_model-00015-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00015-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 362MB/s]\u001b[A\n","pytorch_model-00015-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 367MB/s]\u001b[A\n","pytorch_model-00015-of-00033.bin:  31% 126M/405M [00:00<00:00, 371MB/s] \u001b[A\n","pytorch_model-00015-of-00033.bin:  41% 168M/405M [00:00<00:00, 370MB/s]\u001b[A\n","pytorch_model-00015-of-00033.bin:  52% 210M/405M [00:00<00:00, 374MB/s]\u001b[A\n","pytorch_model-00015-of-00033.bin:  62% 252M/405M [00:00<00:00, 379MB/s]\u001b[A\n","pytorch_model-00015-of-00033.bin:  73% 294M/405M [00:00<00:00, 380MB/s]\u001b[A\n","pytorch_model-00015-of-00033.bin:  83% 336M/405M [00:01<00:00, 239MB/s]\u001b[A\n","pytorch_model-00015-of-00033.bin: 100% 405M/405M [00:01<00:00, 308MB/s]\n","Downloading shards:  45% 15/33 [00:21<00:25,  1.41s/it]\n","pytorch_model-00016-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00016-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 340MB/s]\u001b[A\n","pytorch_model-00016-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 369MB/s]\u001b[A\n","pytorch_model-00016-of-00033.bin:  31% 126M/405M [00:00<00:00, 378MB/s] \u001b[A\n","pytorch_model-00016-of-00033.bin:  41% 168M/405M [00:00<00:00, 383MB/s]\u001b[A\n","pytorch_model-00016-of-00033.bin:  52% 210M/405M [00:00<00:00, 386MB/s]\u001b[A\n","pytorch_model-00016-of-00033.bin:  62% 252M/405M [00:00<00:00, 382MB/s]\u001b[A\n","pytorch_model-00016-of-00033.bin:  73% 294M/405M [00:00<00:00, 378MB/s]\u001b[A\n","pytorch_model-00016-of-00033.bin:  83% 336M/405M [00:00<00:00, 379MB/s]\u001b[A\n","pytorch_model-00016-of-00033.bin: 100% 405M/405M [00:01<00:00, 378MB/s]\n","Downloading shards:  48% 16/33 [00:22<00:22,  1.35s/it]\n","pytorch_model-00017-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00017-of-00033.bin:  10% 41.9M/405M [00:00<00:00, 368MB/s]\u001b[A\n","pytorch_model-00017-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 386MB/s]\u001b[A\n","pytorch_model-00017-of-00033.bin:  31% 126M/405M [00:00<00:00, 387MB/s] \u001b[A\n","pytorch_model-00017-of-00033.bin:  41% 168M/405M [00:00<00:00, 394MB/s]\u001b[A\n","pytorch_model-00017-of-00033.bin:  52% 210M/405M [00:00<00:00, 399MB/s]\u001b[A\n","pytorch_model-00017-of-00033.bin:  62% 252M/405M [00:00<00:00, 395MB/s]\u001b[A\n","pytorch_model-00017-of-00033.bin:  73% 294M/405M [00:00<00:00, 387MB/s]\u001b[A\n","pytorch_model-00017-of-00033.bin:  83% 336M/405M [00:00<00:00, 388MB/s]\u001b[A\n","pytorch_model-00017-of-00033.bin: 100% 405M/405M [00:01<00:00, 359MB/s]\n","Downloading shards:  52% 17/33 [00:23<00:21,  1.32s/it]\n","pytorch_model-00018-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00018-of-00033.bin:   8% 31.5M/405M [00:00<00:01, 303MB/s]\u001b[A\n","pytorch_model-00018-of-00033.bin:  16% 62.9M/405M [00:00<00:01, 288MB/s]\u001b[A\n","pytorch_model-00018-of-00033.bin:  23% 94.4M/405M [00:00<00:01, 277MB/s]\u001b[A\n","pytorch_model-00018-of-00033.bin:  31% 126M/405M [00:00<00:01, 276MB/s] \u001b[A\n","pytorch_model-00018-of-00033.bin:  41% 168M/405M [00:00<00:00, 305MB/s]\u001b[A\n","pytorch_model-00018-of-00033.bin:  52% 210M/405M [00:00<00:00, 330MB/s]\u001b[A\n","pytorch_model-00018-of-00033.bin:  62% 252M/405M [00:00<00:00, 344MB/s]\u001b[A\n","pytorch_model-00018-of-00033.bin:  73% 294M/405M [00:00<00:00, 356MB/s]\u001b[A\n","pytorch_model-00018-of-00033.bin:  83% 336M/405M [00:01<00:00, 360MB/s]\u001b[A\n","pytorch_model-00018-of-00033.bin: 100% 405M/405M [00:01<00:00, 333MB/s]\n","Downloading shards:  55% 18/33 [00:24<00:19,  1.33s/it]\n","pytorch_model-00019-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00019-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 340MB/s]\u001b[A\n","pytorch_model-00019-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 334MB/s]\u001b[A\n","pytorch_model-00019-of-00033.bin:  31% 126M/405M [00:00<00:00, 337MB/s] \u001b[A\n","pytorch_model-00019-of-00033.bin:  41% 168M/405M [00:00<00:00, 350MB/s]\u001b[A\n","pytorch_model-00019-of-00033.bin:  52% 210M/405M [00:00<00:00, 351MB/s]\u001b[A\n","pytorch_model-00019-of-00033.bin:  62% 252M/405M [00:00<00:00, 345MB/s]\u001b[A\n","pytorch_model-00019-of-00033.bin:  73% 294M/405M [00:00<00:00, 346MB/s]\u001b[A\n","pytorch_model-00019-of-00033.bin:  83% 336M/405M [00:00<00:00, 342MB/s]\u001b[A\n","pytorch_model-00019-of-00033.bin: 100% 405M/405M [00:01<00:00, 335MB/s]\n","Downloading shards:  58% 19/33 [00:26<00:18,  1.33s/it]\n","pytorch_model-00020-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00020-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 333MB/s]\u001b[A\n","pytorch_model-00020-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 324MB/s]\u001b[A\n","pytorch_model-00020-of-00033.bin:  31% 126M/405M [00:00<00:00, 319MB/s] \u001b[A\n","pytorch_model-00020-of-00033.bin:  41% 168M/405M [00:00<00:00, 316MB/s]\u001b[A\n","pytorch_model-00020-of-00033.bin:  52% 210M/405M [00:00<00:00, 313MB/s]\u001b[A\n","pytorch_model-00020-of-00033.bin:  62% 252M/405M [00:00<00:00, 313MB/s]\u001b[A\n","pytorch_model-00020-of-00033.bin:  70% 283M/405M [00:00<00:00, 312MB/s]\u001b[A\n","pytorch_model-00020-of-00033.bin:  80% 325M/405M [00:01<00:00, 317MB/s]\u001b[A\n","pytorch_model-00020-of-00033.bin:  91% 367M/405M [00:01<00:00, 318MB/s]\u001b[A\n","pytorch_model-00020-of-00033.bin: 100% 405M/405M [00:01<00:00, 311MB/s]\n","Downloading shards:  61% 20/33 [00:27<00:17,  1.36s/it]\n","pytorch_model-00021-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00021-of-00033.bin:  10% 41.9M/405M [00:00<00:00, 380MB/s]\u001b[A\n","pytorch_model-00021-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 368MB/s]\u001b[A\n","pytorch_model-00021-of-00033.bin:  31% 126M/405M [00:00<00:00, 373MB/s] \u001b[A\n","pytorch_model-00021-of-00033.bin:  41% 168M/405M [00:00<00:00, 383MB/s]\u001b[A\n","pytorch_model-00021-of-00033.bin:  52% 210M/405M [00:00<00:00, 389MB/s]\u001b[A\n","pytorch_model-00021-of-00033.bin:  62% 252M/405M [00:00<00:00, 397MB/s]\u001b[A\n","pytorch_model-00021-of-00033.bin:  73% 294M/405M [00:00<00:00, 383MB/s]\u001b[A\n","pytorch_model-00021-of-00033.bin:  83% 336M/405M [00:00<00:00, 383MB/s]\u001b[A\n","pytorch_model-00021-of-00033.bin: 100% 405M/405M [00:01<00:00, 378MB/s]\n","Downloading shards:  64% 21/33 [00:28<00:15,  1.31s/it]\n","pytorch_model-00022-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00022-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 353MB/s]\u001b[A\n","pytorch_model-00022-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 371MB/s]\u001b[A\n","pytorch_model-00022-of-00033.bin:  31% 126M/405M [00:00<00:00, 362MB/s] \u001b[A\n","pytorch_model-00022-of-00033.bin:  41% 168M/405M [00:00<00:00, 370MB/s]\u001b[A\n","pytorch_model-00022-of-00033.bin:  52% 210M/405M [00:00<00:00, 371MB/s]\u001b[A\n","pytorch_model-00022-of-00033.bin:  62% 252M/405M [00:00<00:00, 374MB/s]\u001b[A\n","pytorch_model-00022-of-00033.bin:  73% 294M/405M [00:00<00:00, 375MB/s]\u001b[A\n","pytorch_model-00022-of-00033.bin:  83% 336M/405M [00:00<00:00, 375MB/s]\u001b[A\n","pytorch_model-00022-of-00033.bin: 100% 405M/405M [00:01<00:00, 372MB/s]\n","Downloading shards:  67% 22/33 [00:30<00:14,  1.29s/it]\n","pytorch_model-00023-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00023-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 323MB/s]\u001b[A\n","pytorch_model-00023-of-00033.bin:  21% 83.9M/405M [00:00<00:01, 307MB/s]\u001b[A\n","pytorch_model-00023-of-00033.bin:  31% 126M/405M [00:00<00:00, 315MB/s] \u001b[A\n","pytorch_model-00023-of-00033.bin:  41% 168M/405M [00:00<00:00, 321MB/s]\u001b[A\n","pytorch_model-00023-of-00033.bin:  52% 210M/405M [00:00<00:00, 320MB/s]\u001b[A\n","pytorch_model-00023-of-00033.bin:  62% 252M/405M [00:00<00:00, 328MB/s]\u001b[A\n","pytorch_model-00023-of-00033.bin:  73% 294M/405M [00:00<00:00, 336MB/s]\u001b[A\n","pytorch_model-00023-of-00033.bin:  83% 336M/405M [00:01<00:00, 341MB/s]\u001b[A\n","pytorch_model-00023-of-00033.bin: 100% 405M/405M [00:01<00:00, 332MB/s]\n","Downloading shards:  70% 23/33 [00:31<00:13,  1.31s/it]\n","pytorch_model-00024-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00024-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 356MB/s]\u001b[A\n","pytorch_model-00024-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 355MB/s]\u001b[A\n","pytorch_model-00024-of-00033.bin:  31% 126M/405M [00:00<00:00, 349MB/s] \u001b[A\n","pytorch_model-00024-of-00033.bin:  41% 168M/405M [00:00<00:00, 345MB/s]\u001b[A\n","pytorch_model-00024-of-00033.bin:  52% 210M/405M [00:00<00:00, 346MB/s]\u001b[A\n","pytorch_model-00024-of-00033.bin:  62% 252M/405M [00:00<00:00, 343MB/s]\u001b[A\n","pytorch_model-00024-of-00033.bin:  73% 294M/405M [00:00<00:00, 336MB/s]\u001b[A\n","pytorch_model-00024-of-00033.bin:  83% 336M/405M [00:00<00:00, 336MB/s]\u001b[A\n","pytorch_model-00024-of-00033.bin: 100% 405M/405M [00:01<00:00, 335MB/s]\n","Downloading shards:  73% 24/33 [00:32<00:11,  1.32s/it]\n","pytorch_model-00025-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00025-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 340MB/s]\u001b[A\n","pytorch_model-00025-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 331MB/s]\u001b[A\n","pytorch_model-00025-of-00033.bin:  31% 126M/405M [00:00<00:00, 327MB/s] \u001b[A\n","pytorch_model-00025-of-00033.bin:  41% 168M/405M [00:00<00:00, 337MB/s]\u001b[A\n","pytorch_model-00025-of-00033.bin:  52% 210M/405M [00:00<00:00, 355MB/s]\u001b[A\n","pytorch_model-00025-of-00033.bin:  62% 252M/405M [00:00<00:00, 368MB/s]\u001b[A\n","pytorch_model-00025-of-00033.bin:  73% 294M/405M [00:00<00:00, 377MB/s]\u001b[A\n","pytorch_model-00025-of-00033.bin:  83% 336M/405M [00:00<00:00, 383MB/s]\u001b[A\n","pytorch_model-00025-of-00033.bin: 100% 405M/405M [00:01<00:00, 366MB/s]\n","Downloading shards:  76% 25/33 [00:34<00:10,  1.30s/it]\n","pytorch_model-00026-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00026-of-00033.bin:  10% 41.9M/405M [00:00<00:00, 383MB/s]\u001b[A\n","pytorch_model-00026-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 390MB/s]\u001b[A\n","pytorch_model-00026-of-00033.bin:  31% 126M/405M [00:00<00:00, 392MB/s] \u001b[A\n","pytorch_model-00026-of-00033.bin:  41% 168M/405M [00:00<00:00, 393MB/s]\u001b[A\n","pytorch_model-00026-of-00033.bin:  52% 210M/405M [00:00<00:00, 395MB/s]\u001b[A\n","pytorch_model-00026-of-00033.bin:  62% 252M/405M [00:00<00:00, 396MB/s]\u001b[A\n","pytorch_model-00026-of-00033.bin:  73% 294M/405M [00:00<00:00, 394MB/s]\u001b[A\n","pytorch_model-00026-of-00033.bin:  83% 336M/405M [00:00<00:00, 385MB/s]\u001b[A\n","pytorch_model-00026-of-00033.bin: 100% 405M/405M [00:01<00:00, 386MB/s]\n","Downloading shards:  79% 26/33 [00:35<00:08,  1.26s/it]\n","pytorch_model-00027-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00027-of-00033.bin:  10% 41.9M/405M [00:00<00:00, 373MB/s]\u001b[A\n","pytorch_model-00027-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 366MB/s]\u001b[A\n","pytorch_model-00027-of-00033.bin:  31% 126M/405M [00:00<00:00, 340MB/s] \u001b[A\n","pytorch_model-00027-of-00033.bin:  41% 168M/405M [00:00<00:00, 331MB/s]\u001b[A\n","pytorch_model-00027-of-00033.bin:  52% 210M/405M [00:00<00:00, 335MB/s]\u001b[A\n","pytorch_model-00027-of-00033.bin:  62% 252M/405M [00:00<00:00, 343MB/s]\u001b[A\n","pytorch_model-00027-of-00033.bin:  73% 294M/405M [00:00<00:00, 324MB/s]\u001b[A\n","pytorch_model-00027-of-00033.bin:  83% 336M/405M [00:01<00:00, 312MB/s]\u001b[A\n","pytorch_model-00027-of-00033.bin: 100% 405M/405M [00:01<00:00, 325MB/s]\n","Downloading shards:  82% 27/33 [00:36<00:07,  1.30s/it]\n","pytorch_model-00028-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00028-of-00033.bin:  10% 41.9M/405M [00:00<00:01, 353MB/s]\u001b[A\n","pytorch_model-00028-of-00033.bin:  21% 83.9M/405M [00:00<00:00, 365MB/s]\u001b[A\n","pytorch_model-00028-of-00033.bin:  31% 126M/405M [00:00<00:00, 379MB/s] \u001b[A\n","pytorch_model-00028-of-00033.bin:  41% 168M/405M [00:00<00:00, 385MB/s]\u001b[A\n","pytorch_model-00028-of-00033.bin:  52% 210M/405M [00:00<00:00, 388MB/s]\u001b[A\n","pytorch_model-00028-of-00033.bin:  62% 252M/405M [00:00<00:00, 389MB/s]\u001b[A\n","pytorch_model-00028-of-00033.bin:  73% 294M/405M [00:00<00:00, 386MB/s]\u001b[A\n","pytorch_model-00028-of-00033.bin:  83% 336M/405M [00:00<00:00, 380MB/s]\u001b[A\n","pytorch_model-00028-of-00033.bin: 100% 405M/405M [00:01<00:00, 376MB/s]\n","Downloading shards:  85% 28/33 [00:38<00:06,  1.39s/it]\n","pytorch_model-00029-of-00033.bin:   0% 0.00/405M [00:00<?, ?B/s]\u001b[A"]}],"source":["!python generate.py \\\n","    --base_model 'baffo32/decapoda-research-llama-7B-hf' \\\n","    --lora_weights '/content/alpaca-lora/output' \\\n","    --prompt_template 'custom' \\\n","    --share_gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7rVMa2ll_G3"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}