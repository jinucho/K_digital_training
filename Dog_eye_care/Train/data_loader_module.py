# -*- coding: utf-8 -*-
"""data_loader_module.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17Vp4Gzf_nz75b_l0iPhtnZ2Uboys9S1y
"""


import torch
from torchvision import transforms
from PIL import Image
import glob
import os
import json
from torch.utils.data import Dataset, DataLoader, random_split


class CustomDataset(Dataset):
    def __init__(self, img_dir, transform=None):
        self.img_dir = img_dir
        self.transform = transform
        self.imgs = []
        self.allowed_labels = ['결막염', '궤양성각막질환', '백내장', '색소침착성각막염', '안검종양', '유루증', '무']

        all_images = glob.glob(os.path.join(img_dir, '*.jpg')) + \
                     glob.glob(os.path.join(img_dir, '*.png')) + \
                     glob.glob(os.path.join(img_dir, '*.jpeg'))

        for img_path in all_images:
            target_path = os.path.splitext(img_path)[0] + '.json'
            if os.path.exists(target_path):
                with open(target_path, 'r', encoding='utf-8') as file:
                    data = json.load(file, )
                    disease_lv_3 = data['label']['label_disease_lv_3']
                    disease = data['label']['label_disease_nm']
                    if disease_lv_3 == '무' or disease in self.allowed_labels:
                        self.imgs.append(os.path.basename(img_path))

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.imgs[idx])
        image = Image.open(img_path).convert("RGB")

        disease_dict = {
            '무': [0, 0, 0, 0, 0, 0],
            '결막염': [1, 0, 0, 0, 0, 0],
            '유루증': [0, 1, 0, 0, 0, 0],
            '궤양성각막질환': [0, 0, 1, 0, 0, 0],
            '백내장': [0, 0, 0, 1, 0, 0],
            '색소침착성각막염': [0, 0, 0, 0, 1, 0],
            '안검종양': [0, 0, 0, 0, 0, 1]
        }

        target_path = os.path.splitext(img_path)[0] + '.json'
        with open(target_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
            disease = data['label']['label_disease_nm']
            # KeyError를 방지하기 위해 get 메서드를 사용
            target = torch.FloatTensor(disease_dict.get(disease, [0, 0, 0, 0, 0, 0]))

        if self.transform:
            image = self.transform(image)

        return image, target


def load_data(data_path):
    # Transform 함수 정의
    transform = transforms.Compose([
        transforms.Resize((224, 224)),  # 무작위 크기와 비율로 크롭한 후, 주어진 크기로 재조정
        transforms.RandomHorizontalFlip(),  # 50% 확률로 수평 뒤집기
        transforms.RandomRotation(30),  # -30도에서 30도 사이로 무작위 회전
        # transforms.ColorJitter(brightness=0.5),    # 밝기를 무작위로 변경
        transforms.RandomVerticalFlip(),  # 50% 확률로 수직 뒤집기
        transforms.ToTensor(),  # 이미지를 PyTorch 텐서로 변환
        transforms.Normalize(  # 이미지 정규화
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
    ])

    # 데이터셋 인스턴스 생성
    dataset = CustomDataset(data_path, transform=transform)
    train_dataset, val_dataset = random_split(dataset, [int(len(dataset)*0.8),int(len(dataset)*0.2)])

    # 데이터 로더 생성
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    valid_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)
    return train_loader, valid_loader


